# redis

## redis简介

Redis是一个**非关系型数据库**，**数据存储在内存**中，因此**读写速度非常快**，被广泛应用于**缓存**方向。

redis 也经常用来做分布式锁。Redis 提供了多种数据类型来支持不同的业务场景。除此之外，redis 支持事务、持久化、Lua 脚本、LRU 驱动时间，多种集群方案。

Redis可以作为**数据库**，实现诸如**点赞、关注、排行等对性能要求极高的互联网需求**；

Redis可以作为**计算工具**，能用很小的代价，**统计诸如PV/UV、用户在线天数**等数据；

Redis还有很多其他的使用场景，例如：可以实现**分布式锁**，可以作为**消息队列**使用。

## Redis和传统的关系型数据库有什么不同？

Redis是一种基于**键值对**的**NoSQL数据库**，而键值对的值是由多种数据结构和算法组成的。Redis的数据都**存储于内存**中，因此它的**速度惊人**，读写性能可达10万/秒，远超关系型数据库。

**关系型数据库**是基于**二维数据表来存储数据**的，它的**数据格式更为严谨，并支持关系查询**。关系型数据库的数据**存储于磁盘**上，可以**存放海量的数据**，但**性能远不如Redis**。

## 为什么要用redis/为什么要用缓存

**高性能、高并发**

**高性能**

假如用户第一个**访问数据库中的某些数据库**的时候，是**从磁盘中取**，**取到内存**，**从内存读取**。

如果将数据库的**数据就放在内存**，我们就会**少一个磁盘的读取时间**，那么**大大增加了我们的读取效率**。

如果数据库的数据改变后，那么我们缓存中的数据跟着改变即可。

![img](https://img-blog.csdnimg.cn/2021020422445078.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

**高并发**

**直接操作缓存能承受的请求远远大于操作数据库的数量**。所以我们可以**将数据库的部分数据转移到缓存中**去，这样**用户的一部分请求会直接到缓存这里而不用经过数据库。**

![img](https://img-blog.csdnimg.cn/20210204224613738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

## 为什么用redis而不用guava/map做缓存

缓存分为**本地缓存和分布式缓存**。**Guava/map 只是本地缓存**，如果 **jvm 关闭后，那么数据会丢失**，在多实例的情况下，每个实例都需要保存一份缓存，缓存不具有一致性。

使用 **redis** 这种为分布式缓存，在**多实例的情况下**，**各实例共用一份缓存数据**，**缓存具有一致性**。缺点是**需要保持 redis 服务的高可用，**整个程序构架上较为复杂。

## Redis是单线程的，为什么还能这么快？

1. 单线程**避免了线程切换和竞争所产生的消耗**；
2. Redis的大部分操作是在**内存上完成**的，这是它实现高性能的一个重要原因；
3. Redis采用了**IO多路复用机制**，使其在网络IO操作中**能并发处理大量的客户端请求**，实现高吞吐率。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/7D358C4626AF51725C251A2611C5DD65.png)

## Redis在持久化时fork出一个子进程，这时已经有两个进程了，怎么能说是单线程呢？

Redis是**单线程**的，主要是指**Redis的网络IO和键值对读写是由一个线程**来完成的。而**Redis的其他功能，如持久化、异步删除、集群数据同步等，则是依赖其他线程来执行的**。所以，说Redis是单线程的只是一种习惯的说法，事实上它的底层不是单线程的。

## redis的线程模型

Redis 内部使用文件事件处理器 file event handler,这个**文件事件处理器是单线程的，所以redis 才叫做单线程的模型。**它采用 IO 多路复用机制同时监听多个 socket，**根据 socket 上的事件来选择对应的事情处理器进行处理**。文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求器、命令回复处理器）

![img](https://img-blog.csdnimg.cn/20210204224921839.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

**多个 socket 可能会并发产生不同的操作**，每个操作**对应不同的文件事件**，但是 **IO 多路复用程序会监听多个 socket**，会**将 socket 产生的事件都放入队列**中，事件分派器**每次从队列中取出一个事件**，把**该事件交给对应的事件处理器**进行处理。

## IO 多路复用

说到 IO 模型，我们必须要了解进程与线程的概念。一个进程至少能创建一个线程，多个线程共享一个进程的内存。程序的最终是靠着线程来完成操作的。

线程执行程序流程是这样的：

1. 给 CPU 进行程序命令的执行。

2. IO 的操作(读取或输出数据)或者请求网络数据。

![img](https://img-blog.csdnimg.cn/20210204225101785.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

IO 复用是指，**多个 IO 流用一个进程处理**。当**用户进程调用了 select 请求服务进程**， 整个**进程会被 Lock**,内核会同时**监视所有 select 里面的 socket**，当其中任何一个 **socket 的数据准备好后**，**select 就会返回一个标志**。**用户进程就会调用 read 操作**，然后**数据从内核拷贝到用户进程**开始处理。


## redis常见数据结构

### String

![img](https://img-blog.csdnimg.cn/20210204225321603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20210204225342613.png)

**incr** 将 key 中储存的数字值增一。如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCR 操作。

**expire** 设置过期时间，以秒为单位

**ttl key** 返回key的过期时间

当一个线程进入后，**setnx**，因为不存在，所以返回 1，可以获得锁。另外线程又来的时候，setnx key 的时候发现上一个线程还在跑，那么就不能获得锁，就不会获取资源。setnx（ 命令在指定的 key 不存在时，为 key 设置指定的值。）

**setnx **命令在指定的 key 不存在时，为 key 设置指定的值。

**setex** Redis Setex 命令为指定的 key 设置值及其过期时间。如果 key 已经存在， SETEX 命令将会替换旧的值。

String 数据结构式简单的 Key-value 类型，value 其实不仅仅可以是 String，也可以是数字。常规 value 缓存应用；常规计数：微博数，粉丝数等。

### **Hash**

常见命令：hget,hset,hgetall 等。

![img](https://img-blog.csdnimg.cn/20210204225458288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

Hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。比如我们可以 hash 数据结构来**存储用户信息，商品信息**等等。

**Hash底层数据结构**

哈希对象有两种编码方案，当同时**满足以下条件**时，哈希对象采用**ziplist编码**，否则采用**hashtable编码**：

- 哈希对象保存的**键值对数量小于512**个；
- 哈希对象保存的所有键值对中的**键和值**，其**字符串长度都小于64字节**。

其中，**ziplist编码采用压缩列表**作为底层实现，而**hashtable**编码采用**字典**作为底层实现。

**压缩列表：**

压缩列表（ziplist），是Redis为了**节约内存**而设计的一种**线性数据结构**，它是由一系列**具有特殊编码的连续内存块构成**的。一个压缩列表可以包含**任意多个节点**，**每个节点可以保存一个字节数组或一个整数值**。

压缩列表的结构如下图所示：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/EDE489BFD41B30C6C8215C25B8BF2BCB.png)

该结构当中的字段含义如下表所示：

|  **属性**   | **类型** | **长度** | **说明**                                                     |
| :---------: | :------: | :------: | :----------------------------------------------------------- |
| **zlbytes** | uint32_t |  4字节   | **压缩列表占用的内存字节数；**                               |
| **zltail**  | uint32_t |  4字节   | 压缩列表表**尾节点距离列表起始地址的偏移量**（单位字节）；   |
|  **zllen**  | uint16_t |  2字节   | 压缩列表包含的**节点数量**，等于UINT16_MAX时，需遍历列表计算真实数量； |
| **entryX**  | 列表节点 |  不固定  | 压缩列表包含的**节点**，节点的长度由节点所保存的内容决定；   |
|  **zlend**  | uint8_t  |  1字节   | 压缩列表的**结尾标识**，是一个固定值0xFF；                   |

其中，压缩列表的节点由以下字段构成：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/F7C97822E36907700FB5DF3F51154ED1.png)

**previous_entry_length（pel）**属性以**字节**为单位，记录当前节点的前一节点的长度，其自身占据**1字节或5**字节：

1. 如果前一节点的长度**小于254**字节，则“pel”属性的长度为**1字节**，前一节点的**长度就保存在这一个字节内**；
2. 如果前一节点的长度**达到254字节**，则“pel”属性的长度为**5字节**，其中**第一个字节被设置为0xFE**，之后的**四个字节用来保存前一节点的长度**；

基于**“pel”**属性，程序便可以**通过指针运算**，根据当前节点的起始地址**计算出前一节点的起始地址**，从而**实现从表尾向表头**的**遍历操作**。

**content**属性负责**保存节点的值（字节数组或整数）**，其类型和长度则由**encoding**属性**决定**，它们的关系如下：

| **encoding**                   | **长度** | **content**                                     |
| :----------------------------- | :------: | :---------------------------------------------- |
| 00 xxxxxx                      |  1字节   | 最大长度为26 -1的字节数组；                     |
| 01 xxxxxx bbbbbbbb             |  2字节   | 最大长度为214-1的字节数组；                     |
| 10 **__** bbbbbbbb ... ... ... |  5字节   | 最大长度为232-1的字节数组；                     |
| 11 000000                      |  1字节   | int16_t类型的整数；                             |
| 11 010000                      |  1字节   | int32_t类型的整数；                             |
| 11 100000                      |  1字节   | int64_t类型的整数；                             |
| 11 110000                      |  1字节   | 24位有符号整数；                                |
| 11 111110                      |  1字节   | 8位有符号整数；                                 |
| 11 11xxxx                      |  1字节   | 没有content属性，xxxx直接存[0,12]范围的整数值； |

**字典：**

字典（dict）又称为**散列表**，是一种用来存储**键值对**的数据结构。C语言没有内置这种数据结构，所以Redis构建了自己的字典实现。

Redis字典的实现主要涉及三个结构体：**字典、哈希表、哈希表节点**。其中，每个哈希表节点保存一个键值对，每个**哈希表由多个哈希表节点构成**，而字典则是对哈希表的进一步封装。这三个结构体的关系如下图所示：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/970CB95850BF97354D08E8B5223CBAA7.png)

其中，dict代表字典，dictht代表哈希表，dictEntry代表哈希表节点。可以看出，**dictEntry是一个数组**，这很好理解，因为一个哈希表里要包含多个哈希表节点。而**dict里包含2个dictht**，**多出的哈希表用于REHASH**。当哈希表保存的键值对数量过多或过少时，需要对哈希表的大小进行扩展或收缩操作，在Redis中，扩展和收缩哈希表是通过REHASH实现的，执行REHASH的大致步骤如下：

1. 为字典的**ht[1]哈希表分配内存空间**

   如果执行的是扩展操作，则ht[1]的大小为**第1个大于等于ht[0].used*2的2n**。如果执行的是收缩操作，则**ht[1]的大小为第1个大于等于ht[0].used的2n**。

2. 将存储在**ht[0]中的数据迁移到ht[1]**上

   重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。

3. 将字典的**ht[1]哈希表晋升为默认哈希表**

   迁移完成后，**清空ht[0]**，再**交换ht[0]和ht[1]的值**，为下一次REHASH做准备。

当满足以下任何一个条件时，程序会自动开始对哈希表执行扩展操作：

1. 服务器目前没有执行bgsave或bgrewriteof命令，并且哈希表的负载因子大于等于1；
2. 服务器目前正在执行bgsave或bgrewriteof命令，并且哈希表的负载因子大于等于5。

为了避免REHASH对服务器性能造成影响，REHASH操作不是一次性地完成的，而是**分多次、渐进式地完成**的。渐进式REHASH的详细过程如下：

1. 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表；
2. 在字典中的索引计数器rehashidx设置为0，表示REHASH操作正式开始；
3. 在REHASH期间，每次对字典执行添加、删除、修改、查找操作时，程序除了执行指定的操作外，还会顺带将ht[0]中位于rehashidx上的所有键值对迁移到ht[1]中，再将rehashidx的值加1；
4. 随着字典不断被访问，最终在某个时刻，ht[0]上的所有键值对都被迁移到ht[1]上，此时程序将rehashidx属性值设置为-1，标识REHASH操作完成。

REHSH期间，字典同时持有两个哈希表，此时的访问将按照如下原则处理：

1. 新添加的键值对，一律被保存到ht[1]中；
2. 删除、修改、查找等其他操作，会在两个哈希表上进行，即程序先尝试去ht[0]中访问要操作的数据，若不存在则到ht[1]中访问，再对访问到的数据做相应的处理。

**跳跃表：**

跳跃表的查找复杂度为平均O(logN)，最坏O(N)，效率堪比红黑树，却远比红黑树实现简单。跳跃表是在**链表的基础上，通过增加索引来**提高查找效率的。

有序链表插入、删除的复杂度为O(1)，而查找的复杂度为O(N)。例：若要查找值为60的元素，需要从第1个元素依次向后比较，共需比较6次才行，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/A9479F35483A8972592990CA58C20FBE.png)

跳跃表是从**有序链表中选取部分节点，组成一个新链表**，并以此作为原始链表的一级索引。再从一级索引中选取部分节点，组成一个新链表，并以此作为原始链表的二级索引。以此类推，可以有多级索引，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/F932B58F002C5A2CA2E94B2FC5DCEF17.png)

跳跃表在查找时，优先从高层开始查找，若next节点值大于目标值，或next指针指向NULL，则从当前节点下降一层继续向后查找，这样便可以提高查找的效率了。

跳跃表的实现主要涉及2个结构体：zskiplist、zskiplistNode，它们的关系如下图所示：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/478F1C196356F6F3651356CE0C66B7E2.png)

其中，蓝色的表格代表zskiplist，红色的表格代表zskiplistNode。zskiplist有指向头尾节点的指针，以及列表的长度，列表中最高的层级。zskiplistNode的头节点是空的，它不存储任何真实的数据，它拥有最高的层级，但这个层级不记录在zskiplist之内。

### **List**

常用命令：lpush,rpush,lpop,rpop,lrang 等

- lpush/rpush：从列表的左侧/右侧添加数据；
- lrange：指定索引范围，并返回这个范围内的数据；
- lindex：返回指定索引处的数据；
- lpop/rpop：从列表的左侧/右侧弹出一个数据；
- blpop/brpop：从列表的左侧/右侧弹出一个数据，若列表为空则进入阻塞状态。

![img](https://img-blog.csdnimg.cn/20210204225552845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)



数据多用linkedList；数据少用ziplist

Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，

LinkedList要维护前后指针，不过带了部分额外的内存开销。

ziplist没有前后指针，保存了上一个节点的长度，也可以双向遍历，当一个结点长度变化，后面节点都要变，连锁更新耗时。

另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做**类似微博那种下拉不断分页的东西（一页一页的往下走）**，性能高。

### Set

常用集合：sadd,spop,smembers,sunion 等

Set 对外提供的功能与 list 类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于轻易实现交集、并集、差集的操作。

比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：

![img](https://img-blog.csdnimg.cn/20210204225854690.png)

底层使用了**intset**和**hashtable**两种数据结构存储的，**intset**我们可以理解为**数组**，**hashtable**就是普通的**哈希表**（key为set的值，value为null）

使用**intset**存储必须满足下面两个条件，**否则使用hashtable**，条件如下：

- 结合对象保存的所有元素都是**整数值**
- 集合对象保存的元素数量**不超过512个**

**intset**

intset内部其实是一个**数组**（int8_t coentents[]数组），而且存储数据的时候是**有序的**，因为在查找数据的时候是通过**二分查找**来实现的。

### Sorted Set

常用命令：zadd,zrang,zrem,zcard 等

和 set 相比，sorted set 增加了一个权重参数 **score**,使得集合中的元素能够按 score 进行有序排列。

举例：在直播系统中，实时排行信息包含在线用户列表，各种礼物排行榜，弹幕消息(可以理解为按消息维度的消息排行榜)等信息，适合使用 Redis 中的 Sorted Set 结构进行储存。

**介绍一下zset类型底层的数据结构**

有序集合对象有2种编码方案，当**同时满足以下条件时**，集合对象采用**ziplist**编码，**否则采用skiplist**编码：

- 有序集合保存的元素数量不超过128个；
- 有序集合保存的所有元素的成员长度都小于64字节。

其中，**ziplist编码的有序集合采用压缩列表**作为底层实现，**skiplist编码的有序集合采用zset**结构作为底层实现。

其中，zset是一个复合结构，它的内部采用**字典和跳跃表**来实现，其源码如下。其中，dict保存了从成员到分支的映射关系，zsl则按分值由小到大保存了所有的集合元素。这样，当按照成员来访问有序集合时可以直接从dict中取值，当按照分值的范围访问有序集合时可以直接从zsl中取值，采用了空间换时间的策略以提高访问效率。

```
typedef struct zset {     
dict *dict;  // 字典，保存了从成员到分值的映射关系；     
zskiplist *zsl; // 跳跃表，按分值由小到大保存所有集合元素； 
} zset;
```

综上，zset对象的底层数据结构包括：**压缩列表、字典、跳跃表**。

**压缩列表：**



### set和zset有什么区别？

set：

- 集合中的元素是**无序、不可重复**的，一个集合最多能存储232-1个元素；
- 集合除了支持对元素的增删改查之外，还支持对多个集合**取交集、并集、差集**。

zset：

- 有序集合保留了集合元素**不能重复**的特点；
- 有序集合会**给每个元素设置一个分数**，并以此作为**排序**的依据；
- 有序集合**不能包含相同的元素**，但是**不同元素的分数可以相同**。

### 三大特殊数据类型

1. **Geospatial（地理位置）**

使用经纬度定位地理坐标并用一个**有序集合zset保存**，所以zset命令也可以使用

- 有效的经度从-180度到180度。
- 有效的纬度从-85.05112878度到85.05112878度。

指定单位的参数 **unit** 必须是以下单位的其中一个：

- **m** 表示单位为米。
- **km** 表示单位为千米。
- **mi** 表示单位为英里。
- **ft** 表示单位为英尺。

2. **Hyperloglog（基数统计）**

计算数据集中不重复的元素的个数。

Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。

网页的访问量（UV）：一个用户多次访问，也只能算作一个人。

3. **BitMaps(位图)**

使用位存储，信息状态只有 0 和 1

Bitmap是一串连续的2进制数字（0或1），每一位所在的位置为偏移(offset)，在bitmap上可执行AND,OR,XOR,NOT以及其它位操作。

保存状态信息，是否签到，是否登录

## 如何利用Redis实现分布式Session？

在web开发中，我们会把用户的**登录信息存储在session里**。而**session是依赖于cookie**的，即服务器创建session时会给它**分配一个唯一的ID**，并且在**响应时创建一个cookie**用于**存储**这个SESSIONID。当客户端收到这个cookie之后，就会**自动保存这个SESSIONID**，并且在**下次访问时自动携带这个SESSIONID**，届时**服务器**就可以**通过这个SESSIONID得到与之对应的session**，从而识别用户的身份。如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/CA7048A5EBAF2E130CF3FE273EFC4C7E.png)

现在的互联网应用，基本都是采用分布式部署方式，即将应用程序部署在多台服务器上，并通过nginx做统一的请求分发。而服务器与服务器之间是隔离的，它们的session是不共享的，这就存在session同步的问题了，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/4E14165FD661832ACE8D2E4DA5449627.png)

如果客户端第一次访问服务器，请求被分发到了服务器A上，则服务器A会为该客户端创建session。如果客户端再次访问服务器，请求被分发到服务器B上，则由于服务器B中没有这个session，所以用户的身份无法得到验证，从而产生了不一致的问题。

解决这个问题的办法有很多，比如可以协调多个服务器，让他们的session保持同步。也可以在分发请求时做绑定处理，即将某一个IP固定分配给同一个服务器。但这些方式都比较麻烦，而且性能上也有一定的消耗。更合理的方式就是采用类似于**Redis这样的高性能缓存服务器**，来**实现分布式session**。

从上面的叙述可知，我们使用session保存用户的身份信息，本质上是要做两件事情。第一是保存用户的身份信息，第二是验证用户的身份信息。如果利用其它手段实现这两个目标，那么就可以不用session，或者说我们使用的是广义上的session了。

具体实现的思路如下图，我们在服务端增加两段程序：

第一是创建令牌的程序，就是在**用户初次访问服务器**时，给它**创建一个唯一的身份标识**，并且使用**cookie封装这个标识**再**发送给客户端**。那么当**客户端下次再访问服务器**时，就会**自动携带这个身份标识**了，这和SESSIONID的道理是一样的，只是改由我们自己来实现了。另外，在返回令牌之前，我们需要将它存储起来，以便于后续的验证。而这个令牌是不能保存在服务器本地的，因为其他服务器无法访问它。因此，我们可以将其存储在服务器之外的一个地方，那么**Redis**便是一个理想的场所。

第二是验证令牌的程序，就是在**用户再次访问服务器时，我们获取到了它之前的身份标识**，那么我们就要**验证一下这个标识是否存在**了。验证的过程很简单，我们从Redis中尝试获取一下就可以知道结果。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/A60691B71D9F189BC9B7EB1A5A16F113.png)



## 说一下Redis中的watch命令

很多时候，要**确保事务中的数据没有被其他客户端修改才执行该事务**。Redis提供了watch命令来解决这类问题，这是一种**乐观锁**的机制。客户端通过**watch命令**，**要求服务器对一个或多个key进行监视**，如果在客户端执行事务之前，这些**key发生了变化**，则**服务器将拒绝执行客户端提交的事务**，并向它**返回一个空值**。

## Redis中，sexnx命令的返回值是什么，如何使用该命令实现分布式锁？

**何时需要分布式锁？**

在分布式的环境下，当**多个server并发修改同一个资源**时，为了**避免竞争就需要使用分布式锁**。那为什么不能使用Java自带的锁呢？因为Java中的锁是面向多线程设计的，它只局限于当前的JRE环境。而**多个server实际上是多进程，是不同的JRE环境**，所以**Java自带的锁机制**在这个场景下是**无效**的。

**在指定的 key 不存在时，为 key 设置指定的值。**

redis Setnx 命令基本语法如下：

```redis
redis 127.0.0.1:6379> SETNX KEY_NAME VALUE
```

一般我们不建议直接使用setnx命令来实现分布式锁，因为**为了避免出现死锁，我们要给锁设置一个自动过期时间**。而**setnx命令和设置过期时间的命令不是原子的，可能加锁成功而设置过期时间失败，**依然存在死锁的隐患。对于这种情况，Redis改进了set命令，给它增加了nx选项，启用该选项时set命令的效果就会setnx一样了。

采用**Redis实现分布式锁，就是在Redis里存一份代表锁的数据**，通常用字符串即可。**采用改进后的setnx命令**（即set...nx...命令）实现分布式锁的思路，以及优化的过程如下：

第一版，这种方式的缺点是**容易产生死锁**，因为**客户端有可能忘记解锁，或者解锁失败**。

```
setnx key value
```

第二版，给**锁增加了过期时间**，避免出现死锁。但这**两个命令不是原子**的，**第二步可能会失败，依然无法避免死锁问题**。

```
setnx key value expire key seconds
```

第三版，通过“**set...nx..**.”命令，将**加锁、过期命令编排到一起**，它们是**原子操作**了，可以**避免死锁**。

```
set key value nx ex seconds 
```

**解锁**：

解锁就是**删除代表锁的那份数据**。

```
del key
```

实际上还有隐患，如下图。**进程A在任务没有执行完毕时，锁已经到期被释放了**。等进程A的**任务执行结束后，它依然会尝试释放锁**，因为它的代码逻辑就是任务结束后释放锁。但是，它的锁早已自动释放过了，它**此时释放的可能是其他线程的锁**。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/59C7A823A30BE4C95CB70B8A1808F120.png)

想要解决这个问题，我们需要解决两件事情：

1. 在加锁时就要给锁**设置一个标识**，**进程要记住这个标识**。当进程解锁的时候，要进行判断，**是自己持有的锁才能释放**，否则不能释放。可以为key赋一个随机值，来充当进程的标识。
2. 解锁时要**先判断、再释放**，这**两步需要保证原子性**，否则**第二步失败的话，就会出现死锁**。而获取和删除命令不是原子的，这就需要采用**Lua脚本**，通过Lua脚本将两个命令编排在一起，而整个Lua脚本的执行是**原子的**。

按照以上思路，优化后的命令如下：

```
# 加锁 
set key random-value nx ex seconds   
# 解锁 
if redis.call("get",KEYS[1]) == ARGV[1] then     
return redis.call("del",KEYS[1]) else     
return 0 
end
```

**基于RedLock算法的分布式锁：**

上述分布式锁的实现方案，是建立在单个主节点之上的。它的潜在问题如下图所示，如果进程A在主节点上加锁成功，然后这个**主节点宕机**了，则**从节点将会晋升为主节点**。若此时**进程B在新的主节点上加锁成果**，之后**原主节点重启**，**成为了从节点**，系统中**将同时出现两把锁**，这是违背锁的唯一性原则的。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/F150CA3203F1CD8A39BB004C990FCB1C.png)

总之，就是**在单个主节点的架构上实现分布式锁，是无法保证高可用的。**若要保证分布式锁的高可用，则可以采用多个节点的实现方案。这种方案有很多，而Redis的官方给出的建议是采用RedLock算法的实现方案。该算法基于多个Redis节点，它的基本逻辑如下：

- 这些**节点相互独立**，**不存在主从复制或者集群协调机制**；
- 加锁：以**相同的KEY向N个实例加锁**，只要**超过一半节点成功**，则**认定加锁成功**；
- 解锁：**向所有的实例发送DEL命令**，进行**解锁**；

RedLock算法的示意图如下，我们可以自己实现该算法，也可以直接使用**Redisson**框架。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/5B9C19EC2AFBB10977147566DF33BE03.png)



## redis 设置过期时间

Redis 中有个设置时间过期的功能，即对储存在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。 

我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。
![img](https://img-blog.csdnimg.cn/20210204230045153.png)

如果假设你设置了一批 Key 只能存活 1 个小时，那么接下来 1 小时后，redis 是怎么对这批key 进行删除的？

**设置想法**

1. **热点数据不设置过期时间**，使其达到“物理”上的永不过期，可以**避免缓存击穿**问题；
2. 在设置过期时间时，可以**附加一个随机数**，**避免大量的key同时过期，导致缓存雪崩**。

### **定期删除+惰性删除**

**定期删除：**

Redis 默认是每隔 **100ms** 就**随机抽取**一些**设置了过期时间的 key**，检查其是否过期，如果过期就删除。

过期扫描不会遍历字典中所有的key，而是采用了一种简单的贪心策略。该策略的删除逻辑如下：

1. 从过期字典中**随机选择20个key**；
2. **删除**这20个key中**已过期**的key；
3. 如果已过期key的**比例超过25%**，则**重复**步骤1。

注意这里是随机抽取的。为什么要随机呢？你想一想加入 redis 存了几十万个Key,每隔 100ms 就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！

**惰性删除：**

定期删除可能会导致很多过期 key 到了时间并没有删除掉。所以就有了惰性删除。假如你的**过期 Key**，靠**定期删除没有被删除掉**，还**停留在内存**里，除非你的系统去**查一下那个 key**， **才会被** redis 给**删除**掉。这就是所谓的**惰性删除**，也是很懒！

![img](https://img-blog.csdnimg.cn/20210204230222778.png)

但是仅仅通过过期时间还是有问题的。我们想一想：如果内存中有很多过期了的 key,然后你也没有及时去查询，那么过期的 key 一直存在，一直堆在内存中，最后导致 redis 内存满了， 无法进行其他新数据的存储。怎么解决这个问题呢？redis 内存淘汰机制。

## redis 内存淘汰机制(MySQL 里有2000W 数据，Redis 中只存20W的数据，如何保证Redis中的数据都是热点数据？)

**Redis提供6种数据淘汰策略：**

1. volatile-lru：从已设置过期时间的数据集(server.db[i].expires)中挑选最近最少使用的数据淘汰    Least recently used

2. volatile-ttl：从已设置过期时间的数据集(server.db[i].expires)中挑选要过期的数据淘汰

3. volatile-random：从已设置过期时间的数据集(server.db[i].expires)中挑选任意数据淘汰

4. allkeys-lru：在数据集中移除最近最少使用的 key(这种方法最常用)

5. allkeys-random：从数据集(server.db[i].dict)中任意选择数据淘汰

6. no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

4.0 版本后增加以下两种：

7. volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
8. allkeys-lfu：移除最不经常使用的key

其中，**volatile**前缀代表从**设置了过期时间的键**中淘汰数据，**allkeys前缀**代表**从所有的键中淘汰数据**。关于后缀，**ttl代表选择过期时间最小的键**，**random代表随机选择键**，需要我们额外关注的是**lru和lfu**后缀，它们分别代表采用lru算法和lfu算法来淘汰数据。

**LRU**（Least Recently Used）是按照最**近最少使用原则**来筛选数据，即最不常用的数据会被筛选出来！

- **标准LRU**：把**所有的数据组成一个链表，表头和表尾分别表示MRU和LRU端，**即**最常使用端和最少使用端**。**刚被访问的数据会被移动到MRU端**，而新增的数据也是刚被访问的数据，也会被移动到MRU端。当**链表的空间被占满时，它会删除LRU端的数据**。
- **近似LRU**：**Redis会记录每个数据的最近一次访问的时间戳（LRU）**。Redis执行写入操作时，若发现内存超出maxmemory，就会执行一次近似LRU淘汰算法。近似LRU会**随机采样N个key，然后淘汰掉最旧的key**，若**淘汰后内存依然超出限制，则继续采样淘汰**。可以通过maxmemory_samples配置项，设置近似LRU每次采样的数据个数，该配置项的默认值为5。

![image-20220704213755456](C:/Users/chm/Desktop/Java学习/面经.assets/image-20220704213755456-16569418767201.png)

LRU算法的不足之处在于，**若一个key很少被访问，只是刚刚偶尔被访问了一次，则它就被认为是热点数据，短时间内不会被淘汰。**

LFU算法正式用于解决上述问题，**LFU**（Least Frequently Used）是Redis4新增的淘汰策略，它**根据key的最近访问频率进行淘汰**。LFU在LRU的基础上，为每个数据增加了一个**计数器**，来**统计这个数据的访问次数**。当使用LFU策略淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出内存。**如果两个数据的访问次数相同，LFU再比较这两个数据的访问时间，把访问时间更早的数据淘汰出内存。**



![put.PNG](C:/Users/chm/Desktop/Java学习/面经.assets/d3612efae05647eeb80c1b997296e225tplv-k3u1fbpfcp-zoom-in-crop-mark3024000.awebp)

![image-20220704213940083](C:/Users/chm/Desktop/Java学习/面经.assets/image-20220704213940083-16569419814713.png)

## redis 持久化机制(怎么保证redis挂掉之后再重启数据可以进行恢复)

### 快照RDB

![img](https://img-blog.csdnimg.cn/20210204231006884.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

从上图中看出，RDB是通过，父进程**创建了一个子进程**，该子进程的作用是**将 redis 内存中的数据快照一份下来，写入一个临时的 RDB 文件**，然后等**持久化完毕后，然后覆盖掉上一次的 RDB 文件**，将**进程数据持久化到硬盘中**，这个过程主进程不进行任何 IO 操作，所以保证了 Redis 的极高性能。

![img](https://img-blog.csdnimg.cn/20210204231030474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

触发规则：

1. **手动触发**

   通过**SAVE**或**BGSAVE命令**触发RDB持久化操作，创建“.rdb”文件；

2. 自动触发

   - 满足**save条件**

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210316174238496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1OTUwMTA5,size_16,color_FFFFFF,t_70)

   注意上图中有一点错误，就是不是当key刚好修改到第5次的时候触发快照机制，而是在**60s内如果redis中的key键至少被修改了5次**，那么会在**第60s这一时刻触发快照规则。**

   - 在执行**flushall**和**flushdb**命令之前会触发快照机制

   ![在这里插入图片描述](C:/Users/chm/Desktop/Java学习/面经.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1OTUwMTA5,size_16,color_FFFFFF,t_70.png)

   注意在**flushall和flushdb命令执行之后**，确实可以触发快照机制生成一个dump.rdb文件，但是请注意这个**dump.rdb文件是空的**，因为快照是在flushall和flushdb命令执行之后生成的；

   - **退出redis**的时候会**触发redis的快照机制**

   ![在这里插入图片描述](C:/Users/chm/Desktop/Java学习/面经.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1OTUwMTA5,size_16,color_FFFFFF,t_70-16560381638098.png)

   当执行redis-cli shutdown的时候，会触发快照机制，快照中的内容是此时redis的16个数据库中的所有的内容，所以在执行redis-cli shutdown这个命令的时候，假设**redis的数据库中没有内容**，那么会生成一个快照，这个**快照中的内容也是空**的，即**生成的dump.rdb文件是空的**；如果关闭redis数据库的时候，redis的16个数据库中有数据，那么会生成一个快照，这个快照中的内容就是redis的16个数据库中的内容，会存储到dump.rdb这个持久化文件中；

其中，**SAVE命令执行期间，Redis服务器将阻塞**，直到**“.rdb”文件创建完毕为止**。而**BGSAVE命令是异步版本的SAVE命令**，它会使用Redis服务器进程的子进程，创建“.rdb”文件。**BGSAVE命令在创建子进程时会存在短暂的阻塞，之后服务器便可以继续处理其他客户端的请求**。总之，**BGSAVE**命令是**针对SAVE阻塞**问题做的**优化**，Redis内部所有涉及RDB的操作都采用BGSAVE的方式，而SAVE命令已经废弃！

BGSAVE命令的执行流程，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/939F2BF55AFF0E48184628AE3B19BB67.png)

BGSAVE命令的原理，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/7195949B05E80D8EEBFE084774FF8753.png)

**只要把rdb文件放在我们的redis的启动目录的下面，那么在redis启动的时候就会自动检查dump.rdb文件，然后恢复其中的数据。**

优点：

1. **适合大规模的数据恢复**
2. 对数据的**完整性要求不高**

缺点：

​	**每次运行都要执行fork操作创建子进程**，属于**重量级操作**，不宜频繁执行。

​	需要一定的时间间隔进行操作！如果**中途宕机**，那么**最后一次修改的数据的就没了fork 进度**的时候，会占用一定的内存空间。

### 只追加文件 AOF(append-only file)持久化

与快照持久化相比，AOF 持久化的**实时性更好**，但是 redis 的默认不是 AOF，所以要去配置文件中开启。

```
appendonly yes         # 启用AOF appendfilename "appendonly.aof"  # 设置文件名
```

AOF以**文本协议格式**写入命令，如：

```
*3\r\n$3\r\nset\r\n$5\r\nhello\r\n$5\r\nworld\r\n
```

文本协议格式具有如下的优点：

1. 文本协议具有**很好的兼容性**；
2. 直接采用文本协议格式，可以**避免二次处理的开销**；
3. 文本协议具有**可读性**，**方便**直接**修改和处理**。

只追加文件，那么追加的是什么呢？什么会更改数据呢？当然是写操作了。所以 AOF 干的事就是**把写操作都给他记录下来**，**重启 redis 之后**，再**执行**这个记录了**写操作的文件appendonly.aof**

![img](C:/Users/chm/Desktop/Java学习/面经.assets/72D05C716050D5C022C41B7911FAED6D.png)

![img](https://img-blog.csdnimg.cn/20210204231238208.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

1. 父进程fork一个子进程

2. 子进程根据内存中的数据快照，向临时AOF文件写入重建数据库状态的命令
3. 父进程的写命令放入缓存，同时写入原AOF；
4. 子进程写入完成后，通知父进程
5. 父进程将缓存的写命令写入临时AOF文件
6. 父进程将临时AOF文件替换旧的AOF文件
7. 父进程后面的命令都写入新的AOF文件

就算这个 aof 有错误，redis 内部有一个 redis-check-aof 可以去修复 aof 文件

![img](https://img-blog.csdnimg.cn/20210204231307650.png)

1.**每次修改都记录**

2.**一秒记录一次**

3.操作系统自己同步数据

**重写机制：**

AOF 随着命令的越来越多，他的容量也会越来越大。但是数据库的数据是可以由不同的语句得到。比如 list，我们先分别 rpush A~F，然后在 lpop A~B。那么 AOF 文件直接存 rpush C~F 即可，这就节约空间了。这就是其中有些命令是可以多行合并成一行的！！

1. 当程序调用write对文件写入时，系统**不会直接把数据写入硬盘**，而是**先将数据写入内存的缓冲区中**；
2. 当**达到特定的时间周期或缓冲区写满**时，系统才会**执行flush**操作，将缓冲区中的**数据冲洗至硬盘**中；

这种优化机制虽然提高了性能，但也给程序的**写入操作带来了不确定性**。

1. 对于AOF这样的持久化功能来说，冲洗机制将直接影响AOF持久化的安全性；
2. 为了消除上述机制的不确定性，Redis向用户提供了**appendfsync**选项，来**控制系统冲洗AOF的频率**；
3. Linux的glibc提供了**fsync**函数，可以将**指定文件强制从缓冲区刷到硬盘**，上述选项正是基于此函数。

appendfsync选项的取值和含义如下：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/4C081F8534BED6D701B6F23A7E3AE995.png)

优点：

1. 不容易丢失数据，因为复制频率高。

缺点：

1. 对于数据文件来说，**AOF文件存储的是协议文本**，aof **远远大于 rdb**，**修复的速度**也比 rdb **慢**！
2. AOF在进行**重写时也需要创建子进程**，在**数据库体积较大时将占用大量资源**，aof **运行效率**也比 rdb **慢**，会导致**服务器的短暂阻塞**。所以 redis 的默认配置是 rdb.

### RDB-AOF混合持久化：

Redis从4.0开始引入RDB-AOF混合持久化模式，这种模式是**基于AOF持久化**构建而来的。用户可以通过配置文件中的“**aof-use-rdb-preamble yes**”配置项开启AOF混合持久化。Redis服务器在执行AOF重写操作时，会按照如下原则处理数据：

- 像执行BGSAVE命令一样，根据数据库当前的状态**生成相应的RDB数据，并将其写入AOF文件中**；
- 对于**重写之后执行的Redis命令**，则以**协议文本的方式追加到AOF文件的末尾**，即RDB数据之后。

**理论上来说，AOF/RDB-AOF持久化可以将丢失数据的窗口控制在1S之内。**

## redis 事务

Redis 事务提供了一种将**多个命令请求打包**，然后**一次性、按顺序地执行多个命令**的机制， 并且在**事务执行期间**，服务器**不会中断事务而去执行其他客户端的命令**请求，它会**将事务中的所有命令都执行完毕**，然后**才会去处理其他客户端的命令请求**。

**Multi 开始一个事务，EXEC 触发事务**

支持特性：**一致性和隔离性**

原子性: 因为打包的命令**中有一条执行错误**，其他的**一样会执行**。

持久性：**不会同步到硬盘**。

**一致性是数据库处理前后结果应与其所抽象的客观世界中真实状况保持一致。**


## 缓存击穿

缓存击穿是指**缓存中没有**但**数据库中有**的数据(一般是缓存时间到期)，这时由于并发用户特别多，同时读缓存没有读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

1. 设置**热点数据永不过期**。
2. 加**互斥锁**

## **缓存穿透**

用户想要查询一个数据，发现 redis **内存数据库没有**，也就是缓存没有命中，于是向**数据库查询也没有**，于是**查询失败**。当**用户很多的时候**，缓存都没有明红，于是**都去请求持久层的数据库**。这会**给持久层的数据库造成很大的压力**，相等于出现了缓存穿透。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70.png)

**解决方式**

### **布隆过滤器**

给用户推荐新闻时，要去掉重复的新闻，就可以利用布隆过滤器，判断该新闻是否已经推荐过。

布隆过滤器是一种数据结构，对所有可能查询的 key 以 hash 形式存储，在控制层先进行校验，不负责则丢弃，从而避免了对底层存储系统的查询压力。

![img](https://img-blog.csdnimg.cn/20210204232452135.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20210204232458779.png)

布隆过滤器就是一个**很长的二进制数组**，如果**存在就是 1**，**不存在就是 0**.

![img](https://img-blog.csdnimg.cn/20210204232519190.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

要经过 **3 个哈希函数**，去**存到下标位置**。

增：通过多个哈希函数，分别到**计算出的位置置为 1**

查：**查询的时候都要查询**，**都是 1 才算存在**。还是通过多个哈希函数

删：**很难进行删除操作**，如果**把 1 换成 0**，可能一**个位置存在多个数。可能存在哈希冲突**

![img](https://img-blog.csdnimg.cn/20210204232557441.png)

优点：

1. 是二进制数，**空间需求小**
2. **插入和查询的速度快**，因为是计算哈希值，再由哈希值映射到坐标。时间复杂度：O（K） k 个哈希函数。
3. **保密性好**，存储的都是 0,1.

缺点：

1. **很难做删除**

2. **容易误判**，不同的数据可能计算出来相同的哈希值。比如上面查询 hello，但是你好的哈希值跟 hello 一样，所以为判断存在。 只能减少误判的概率，可以在代码里设置误判率。误判率越小，计算时间就越大。

减少误判率，增加哈希函数，算出的哈希值也就越多，降低相同哈希值的概率，那么空间就会越大。

### 缓存空对象

 当存储层不命中后，**及时返回的空对象也将其缓存起来**，同时会**设置一个过期时间**，后**下一次访问的时候直接返回一个空对象**，保护后端数据库。

但是这种方法会存在两个问题：

1. 这样一来**缓存里会存在较多的空对象，比较浪费内存空间**。
2. 即使对**空值设置了过期时间**，还是**会存在缓存层和数据层**会有**一段时间窗口的不一致**，这对于需要保持一致性的也会有影响。

## 缓存雪崩

**缓存大面积失效，后面的请求都去访问数据库，造成数据库短时间内承受大量请求而挂掉。**

比如在写本文的时候，马上就要到双十二零点了，会快就会迎来一波抢购，这波商品时间比较集中的放入了缓存，假设缓存一个小时，那么到了凌晨一点钟的时候，这批商品的缓存就都过期了。而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。于是所 i 有的请求都会达到存储层，储存层的调用量会暴增，造成储存层也会挂掉的情况.

![img](https://img-blog.csdnimg.cn/20210204231907725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

**解决方案：**
**redis 高可用**:既然一台 redis 挂掉了，那么就多增几台 redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的**集群**。

1. **主从复制**

​	将**一台Redis服务器的数据，复制到其他的Redis服务器**。前者称为**主节点**（Master/Leader）,后者称为**从节点**（Slave/Follower），**数据的复制是单向**的！只能由**主节点复制到从节点**（主节点以写为主、从节点以读为主）。

- **从机只能读不能写**，**主机可读可写**
- 当**主机断电宕机**后，默认情况下**从机的角色不会发生变化** ，**集群中只是失去了写操作**，当**主机恢复**以后，又会**连接上从机恢复原状**。

- 当**从机断电宕机**后，**若不是使用配置文件配置的从机**，再次**启动后无法获取之前主机的数据**，若**此时重新配置称为从机**，又**可以获取到主机的所有数据**。这里就要提到一个同步原理。

- 第二条中提到，默认情况下，主机故障后，不会出现新的主机，有两种方式可以产生新的主机：
  - **从机手动执行命令`slaveof no one`,这样执行以后从机会独立出来成为一个主机**
  - 使用**哨兵模式**（自动选举）

2. **哨兵模式**

- 通过发送命令，让**Redis服务器返回监控其运行状态**，包括**主服务器和从服务器。**
- 当**哨兵监测到master宕机**，会**自动将slave切换成master**，然后通过**发布订阅模式**通知其他的**从服务器，修改配置文件，让它们切换主机**。

优点：

- **哨兵模式是基于主从模式的**，所有**主从的优点，哨兵模式都具有。**
- **主从可以自动切换，系统更健壮，可用性更高。**

缺点：

- 具有主从模式的缺点，**每台机器上的数据是一样的，内存的可用性较低。**
- **Redis较难支持在线扩容**，在**集群容量达到上限时在线扩容会变得很复杂**。



**限流降级**：在缓存失效后，通过**加锁或者队列来控制数据库写缓存的线程数量**。比如**某个key 值允许一个线程查询数据和写缓存，其他想要操作这个 key 那么必须等待。**
**数据预热**:   先**把可能的数据先访问一次**，**访问的数据加入缓存中**，再**设置不同的过期时间**，让缓存**失效时间点尽量均匀**。

**血崩与击穿区别**

**击穿**是查**单个key**，**雪崩**是**一群key**到期

## 如何保证缓存与数据库的双写一致性？

四种同步策略：

想要保证**缓存与数据库的双写一致**，一共有4种方式，即4种同步策略：

1. 先更新缓存，再更新数据库；
2. 先更新数据库，再更新缓存；
3. 先删除缓存，再更新数据库；
4. **先更新数据库，再删除缓存。**

从这4种同步策略中，我们需要作出比较的是：

1. 更新缓存与删除缓存哪种方式更合适？
2. 应该先操作数据库还是先操作缓存？

更新缓存还是删除缓存：

下面，我们来分析一下，**应该采用更新缓存还是删除缓存的方式**。

- 更新缓存

  优点：**每次数据变化都及时更新缓存**，所以查询时不容易出现未命中的情况。

  缺点：更新缓存的**消耗比较大**。如果数据需要经过复杂的计算再写入缓存，那么**频繁的更新缓存，就会影响服务器的性能**。如果是写入数据频繁的业务场景，那么可能频繁的更新缓存时，却没有业务读取该数据。

- 删除缓存

  优点：**操作简单**，无论更新操作是否复杂，都是**将缓存中的数据直接删除**。

  缺点：删除缓存后，**下一次查询缓存会出现未命中**，这时**需要重新读取一次数据库**。

从上面的比较来看，一般情况下，删除缓存是更优的方案。

先操作数据库还是缓存：

下面，我们再来分析一下，应该先操作数据库还是先操作缓存。

首先，我们将先删除缓存与先更新数据库，在出现失败时进行一个对比：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/A8EAB406CDF2717DDC4C9AB91E37092E.png)

如上图，是先删除缓存再更新数据库，在出现失败时可能出现的问题：

1. 进程**A删除缓存成功**；
2. 进程**A更新数据库失败**；
3. 进程**B从缓存中读取数据**；
4. 由于缓存被删，进程**B无法从缓存中得到数据，进而从数据库读取数据**；
5. 进程**B从数据库成功获取数据**，然后**将数据更新到了缓存**。

最终，缓存和数据库的数据是一致的，但仍然是旧的数据。而我们的期望是二者数据一致，并且是新的数据。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/49738596B86BC1711C57C412E1E61983.png)

如上图，是**先更新数据库再删除缓存**，在出现失败时可能出现的问题：

1. 进程**A更新数据库成功**；
2. 进程**A删除缓存失败**；
3. 进程**B读取缓存成功**，由于缓存删除失败，所以进程B读取到的是旧的数据。

最终，缓存和数据库的数据是不一致的。

经过上面的比较，我们发现在出现失败的时候，是无法明确分辨出先删缓存和先更新数据库哪个方式更好，以为它们都存在问题。后面我们会进一步对这两种方式进行比较，但是在这里我们先探讨一下，上述场景出现的问题，应该如何解决呢？

实际上，无论上面我们采用哪种方式去同步缓存与数据库，在第二步出现失败的时候，都建议采用**重试机制**解决，因为最终我们是要解决掉这个错误的。而为了避免重试机制影响主要业务的执行，一般建议重试机制采用异步的方式执行，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/494AA2EB05BD1FA88DF2602827EB2FB3.png)

这里我们按照先更新数据库，再删除缓存的方式，来说明重试机制的主要步骤：

1. 更新数据库成功；
2. 删除缓存失败；
3. 将此数据加入消息队列；
4. 业务代码消费这条消息；
5. 业务代码根据这条消息的内容，发起重试机制，即从缓存中删除这条记录。

好了，下面我们再将先删缓存与先更新数据库，在没有出现失败时进行对比：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/3E859D74665EAEDFB0EC7B329AB61018.png)

如上图，是先删除缓存再更新数据库，在没有出现失败时可能出现的问题：

1. 进程**A删除缓存成功**；
2. 进程B读取缓存失败；
3. 进程B读取数据库成功，得到旧的数据；
4. 进程B将旧的数据成功地更新到了缓存；
5. 进程**A将新的数据成功地更新到数据库**。

可见，进程A的两步操作均成功，但由于存在**并发**，在这两步之间，进程B访问了缓存。最终结果是，缓存中存储了旧的数据，而数据库中存储了新的数据，二者数据不一致。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/B0F33AE7D79266FEE21B3EABF6C0EBCE.png)

如上图，是先更新数据库再删除缓存，再没有出现失败时可能出现的问题：

1. 进程**A更新数据库成功**；
2. 进程B读取缓存成功；
3. 进程**A删除缓存成功**。

可见，最终缓存与数据库的数据是一致的，并且都是最新的数据。但进程B在这个过程里读到了旧的数据，可能还有其他进程也像进程B一样，在**这两步之间读到了缓存中旧的数据**，但因为这两步的执行速度会比较快，所以影响不大。对于这两步之后，其他进程再读取缓存数据的时候，就不会出现类似于进程B的问题了。

经过对比你会发现，**先更新数据库、再删除缓存是影响更小的方案**。如果第二步出现失败的情况，则可以采用重试机制解决问题。

上面我们提到，如果是先删缓存、再更新数据库，在没有出现失败时可能会导致数据的不一致。如果在实际的应用中，出于某些考虑我们需要选择这种方式，那有办法解决这个问题吗？答案是有的，那就是采用延时双删的策略，**延时双删**的基本思路如下：

**延时双删**

1. 删除缓存；
2. 更新数据库；
3. sleep N毫秒；
4. 再次删除缓存。

**阻塞一段时间之后，再次删除缓存**，就可以把这个过程中缓存中不一致的数据删除掉。而具体的时间，要评估你这项业务的大致时间，按照这个时间来设定即可。

采用读写分离的架构怎么办？

如果数据库采用的是读写分离的架构，那么又会出现新的问题，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/49BCF6CB1360234D0D9040255E0C0B0C.png)

进程A先删除缓存，再更新主数据库，然后主库将数据同步到从库。而在主从数据库同步之前，可能会有进程B访问了缓存，发现数据不存在，进而它去访问从库获取到旧的数据，然后同步到缓存。这样，最终也会导致缓存与数据库的数据不一致。这个问题的解决方案，依然是采用延时双删的策略，但是在评估延长时间的时候，要考虑到主从数据库同步的时间。

**第二次删除失败**了怎么办？

如果第二次删除依然失败，则可以**增加重试的次数**，但是这个次数**要有限制**，当**超出一定的次数时，要采取报错、记日志、发邮件提醒等措施**。

## **如何解决Redis的并发竞争Key问题**

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同！

推荐方案：[**分布式锁**](https://so.csdn.net/so/search?q=分布式锁&spm=1001.2101.3001.7020)(zookeeper 和 redis 都可以实现分布式锁)。(如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能)

## Redis为何这么快

1. 完全**基于内存**，绝大部分请求是纯粹的**内存操作，非常快速**。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2. **数据结构简单**，**对数据操作也简单**，Redis中的数据结构是专门进行设计的
3. 采用**单线程**，避免了不必要的上下文切换和竞争条件，也不存在多线程的切换导致消耗CPU，不用去考虑各种锁的问题。
4. 使用多路I/O复用模型，非阻塞IO;

## 如何实现Redis的高可用？

实现Redis的高可用，主要有**哨兵**和**集群**两种方式。

### 哨兵

Redis Sentinel（哨兵）是一个**分布式架构**，它包含**若干个哨兵节点和数据节点**。**每个哨兵节点会对数据节点和其余的哨兵节点进行监控**，当发现**节点不可达**时，**会对节点做下线标识**。**如果**被标识的**是主节点**，它就**会与其他的哨兵节点进行协商**，当**多数哨兵节点都认为主节点不可达时**，它们便会**选举出一个哨兵节点来完成自动故障转移**的工作，同时还会**将这个变化实时地通知给应用方**。整个过程是**自动**的，不需要人工介入，有效地解决了Redis的**高可用**问题！

**一组哨兵可以监控一个主节点，也可以同时监控多个主节点**，两种情况的拓扑结构如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/7973F150721F816D3E2548C1F02CED35.png)

**哨兵节点**包含如下的特征：

1. 哨兵节点会**定期监控数据节点**，**其他哨兵节点是否可达**；
2. 哨兵节点会将**故障转移的结果通知给应用方**；
3. 哨兵节点可以**将从节点晋升为主节点**，并维护后续正确的主从关系；
4. 哨兵模式下，**客户端连接的是哨兵节点集合**，从中**获取主节点信息**；
5. 节点的**故障判断**是由**多个哨兵节点共同完成**的，可有效地防止误判；
6. 哨兵节点集合是由**多个哨兵节点**组成的，即使**个别哨兵节点不可用，整个集合依然是健壮的**；
7. 哨兵节点也是独立的Redis节点，是特殊的Redis节点，它们**不存储数据**，只支持部分命令。

### 集群（多台Redis抗高并发访问该怎么设计？）（如果并发量超过30万，怎么设计Redis架构？）

Redis集群采用**虚拟槽分区来实现数据分片**，它把所有的**键根据哈希函数映射到0-16383整数槽内**，计算公式为slot=CRC16(key)&16383，**每一个节点负责维护一部分槽以及槽所映射的键值数据**。虚拟槽分区具有如下特点：

1. **解耦数据和节点**之间的关系**，简化了节点扩容和收缩**的难度；
2. 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据；
3. 支持**节点、槽、键之间的映射查询**，用于数据路由，在线伸缩等场景。

Redis集群中数据的分片逻辑如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/2B3170169B19552123C5487746142DF6.png)

Redis集群的功能限制：

Redis集群方案在扩展了Redis处理能力的同时，也带来了一些使用上的限制：

1. key**批量操作支持有限**。如mset、mget，目前只支持**具有相同slot值的key**执行批量操作。对于映射为**不同slot值的key**由于执行mset、mget等操作**可能存在于多个节点上所以不被支持**。
2. key**事务操作支持有限**。同理只支持**多key在同一节点上的事务操作**，当多个key分布在不同的节点上时无法使用事务功能。
3. key作为数据分区的最小粒度，因此不能将一个大的键值对象（如hash、list等）映射到不同的节点。
4. 不支持多数据库空间。**单机下的Redis可以支持16个数据库**，**集群模式下只能使用一个数据库空间**，即DB0。
5. **复制结构只支持一层，从节点只能复制主节点**，不支持嵌套树状复制结构。

Redis集群的通信方案：

在分布式存储中需要提供维护节点元数据信息的机制，所谓元数据是指：节点负责哪些数据，是否出现故障等状态信息。常见的元数据维护方式分为：集中式和P2P方式。

Redis集群采用**P2P的Gossip（流言）协议**，Gossip协议的工作原理就是**节点彼此不断通信交换信息**，**一段时间后所有的节点都会知道集群完整的信息**，这种方式类似**流言传播**。通信的大致过程如下：

1. 集群中**每个节点都会单独开辟一个TCP通道**，用于**节点之间彼此通信**，**通信端口号在基础端口号上加10000**；
2. **每个节点**在**固定周期**内通过特定规则**选择几个节点发送ping消息**；
3. **接收ping消息的节点**用**pong消息作为响应**。

其中，Gossip协议的主要职责就是**信息交换**，而信息交换的载体就是节点彼此发送的Gossip消息，Gossip消息分为：**meet消息、ping消息、pong消息、fail消息**等。

- **meet消息**：**用于通知新节点加入**，消息发送者通知接受者加入到当前集群。meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换。
- **ping消息**：集群内交换最频繁的消息，集群内**每个节点每秒向多个其他节点发送ping消息**，用于**检测节点是否在线和交换彼此状态信息**。ping消息**封装了自身节点和一部分其他节点的状态数据**。
- **pong消息**：当**接收到meet、ping消息时**，作为**响应消息**回复**给发送方确认消息正常通信**。pong消息内**封装了自身状态数据**，节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。
- **fail消息**：当**节点判定集群内另一个节点下线时**，会向集群内**广播一个fail消息**，**其他节点接收到fail消息之后把对应节点更新为下线状态**。

虽然Gossip协议的信息交换机制具有天然的分布式特性，但它是**有成本**的。因为Redis集群内部需要频繁地进行节点信息交换，而**ping/pong消息会携带当前节点和部分其他节点的状态数据**，势必会**加重带宽和计算的负担**。所以，Redis集群的Gossip协议**需要兼顾信息交换的实时性和成本的开销**。

- 集群里的每个节点默认**每隔一秒钟**就会**从已知节点列表中随机选出五个节点，**然后**对**这五个节点中**最长时间没有发送过PING消息的节点发送PING消息**，以此来检测被选中的节点是否在线。
- 如果**节点A最后一次收到节点B发送的PONG消息的时间**，**距离当前时间已经超过了**节点A的**超时选项设置时长的一半**（cluster-node-timeout/2），那么**节点A也会向节点B发送PING消息**，这可**以防止节点A因为长时间没有随机选中节点B作为PING消息的发送对象而导致对节点B的信息更新滞后。**
- 每个消息主要的数据占用：**slots槽数组（2KB）**和**整个集群1/10的状态数据**（10个节点状态数据约1KB）。

## Redis的主从同步是如何实现的？

从2.8版本开始，Redis使用**psync命令**完成主从数据同步，同步过程分为**全量复制**和**部分复制**。**全量复制**一般用于**初次复制的场景**，**部分复制**则用于**处理因网络中断等原因造成数据丢失**的场景。psync命令需要以下参数的支持：

1. **复制偏移量**：主节点处理写命令后，会把命令长度做累加记录，从节点在接收到写命令后，也会做累加记录；**从节点会每秒钟上报一次自身的复制偏移量**给主节点，而**主节点则会保存从节点的复制偏移量**。
2. **积压缓冲区**：保存在**主节点**上的一个**固定长度的队列**，**默认大小为1M**，当主节点有连接的从节点时被创建；**主节点处理写命令时，不但会把命令发送给从节点，还会写入积压缓冲区**；缓冲区是**先进先出的队列**，可以**保存最近已复制的数据，用于部分复制和命令丢失的数据补救。**
3. **主节点运行ID**：每个Redis节点启动后，都会动态分配一个**40位的十六进制字符串作为运行ID**；如果**使用IP和端口的方式标识主节点，那么主节点重启变更了数据集（RDB/AOF），从节点再基于复制偏移量复制数据将是不安全的**，因此当**主节点的运行ID变化后，从节点将做全量复制。**

psync命令的执行过程以及返回结果，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/6771D78AF7BCF3E4907366DDE0D79259.png)

全量复制的过程，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/946920CB89AE5D191202B12E9FE9F4F7.png)

部分复制的过程，如下图：

![img](C:/Users/chm/Desktop/Java学习/面经.assets/38A020497C3D4B30EF561E8415EAFAB1.png)

## 说一说Redis集群的应用和优劣势

**优势：**

Redis Cluster是Redis的分布式解决方案，在3.0版本正式推出，有效地**解决了Redis分布式方面的需求**。当遇到**单机内存、并发、流量等瓶颈**时，可以**采用Cluster架构方案达到负载均衡的目的**。

**劣势：**

Redis集群方案在扩展了Redis处理能力的同时，也带来了一些使用上的限制：

1. **key批量操作支持有限**。如mset、mget，目前**只支持具有相同slot值的key执行批量操作**。对于映射为不同slot值的key由于执行mset、mget等操作可能存在于多个节点上所以不被支持。
2. key**事务操作支持有限**。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。
3. key作为数据分区的最小粒度，因此**不能将一个大的键值对象（如hash、list等）映射到不同的节点**。
4. **不支持多数据库空间**。**单机下的Redis可以支持16个数据库，集群模式下只能使用一个数据库空间**，即DB0。
5. 复制结构只支持一层，**从节点只能复制主节点**，**不支持嵌套树状复制结构**。