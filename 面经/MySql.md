# MySql

## 简介

Mysql是**关系型**数据库管理系统**(DBMS**)，Sql是结构化查询语言。

DBMS负责**执行SQL**去**操作数据库**(DB,一般存储在硬盘上)中的数据。

## SQL

### 介绍一下数据库分页

在MySQL中，SELECT语句默认返回所有匹配的行，它们可能是指定表中的每个行。为了返回第一行或前几行，可使用LIMIT子句，以实现分页查询。LIMIT子句的语法如下：

```mysql
-- 在所有的查询结果中，返回前5行记录。 
SELECT prod_name FROM products LIMIT 5; 
-- 在所有的查询结果中，从第5行开始，返回5行记录。 
SELECT prod_name FROM products LIMIT 5,5;
```

带一个值的LIMIT总是从第一行开始，给出的数为返回的行数。带两个值的LIMIT可以指定从行号为第一个值的位置开始。

**优化LIMIT分页：**

在**偏移量非常大**的时候，例如 **LIMIT 10000,20** 这样的查询，这时MySQL需要查询10020条记录然后只返回最后20条，前面的10000条记录都将被抛弃，这样的代价是非常高的。如果所有的页面被访问的频率都相同，那么这样的查询平均需要访问半个表的数据。要优化这种查询，要么是在页面中限制分页的数量，要么是优化大偏移量的性能。

优化此类分页查询的一个最简单的办法就是尽可能地**使用索引覆盖扫描**，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候，这样做的效率会提升非常大。考虑下面的查询：

```sql
SELECT film_id,description FROM sakila.film ORDER BY title LIMIT 50,5;
```

如果这个表非常大，那么这个查询最好改写成下面的样子：

```sql
SELECT film.film_id,film.description  FROM sakila.film INNER JOIN (SELECT film_id FROM sakila.film ORDER BY title LIMIT 50,5 ) AS lim USING(film_id);
```

这里的“延迟关联”将大大提升查询效率，它让MySQL扫描尽可能少的页面，**获取需要访问的记录后再根据关联列回原表查询需要的所有列**。这个技术也可以用于优化关联查询中的LIMIT子句。

有时候也可以将LIMIT查询**转换为已知位置的查询**，让MySQL通过范围扫描获得对应的结果。例如，如果在一个位置列上有索引，并且预先计算出了边界值，上面的查询就可以改写为：

```sql
SELECT film_id,description FROM skila.film WHERE position BETWEEN 50 AND 54 ORDER BY position;
```

对数据进行排名的问题也与此类似，但往往还会同时和GROUP BY混合使用，在这种情况下通常都需要预先计算并存储排名信息。

LIMIT和OFFSET的问题，其实是OFFSET的问题，它会导致MySQL扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上次取数的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET。例如，若需要按照租赁记录做翻页，那么可以根据最新一条租赁记录向后追溯，这种做法可行是因为租赁记录的主键是单调增长的。首先使用下面的查询获得第一组结果：

```sql
SELECT * FROM sakila.rental ORDER BY rental_id DESC LIMIT 20;
```

假设上面的查询返回的是主键16049到16030的租赁记录，那么下一页查询就可以从16030这个点开始：

```sql
SELECT * FROM sakila.rental WHERE rental_id < 16030 ORDER BY rental_id DESC LIMIT 20;
```

该技术的好处是无论翻页到多么后面，其性能都会很好。

### 介绍一下SQL中的聚合函数

**参考答案**

常用的聚合函数有**COUNT()**、**AVG()**、**SUM()**、**MAX()**、**MIN()**，下面以MySQL为例，说明这些函数的作用。

**COUNT()函数：**

COUNT()函数统计**数据表中包含的记录行的总数**，或者根据查询结果返回列中包含的数据行数，它有两种用法：

- COUNT(*)计算表中总的行数，不管某列是否有数值或者为空值。
- COUNT(字段名)计算指定列下总的行数，计算时将忽略空值的行。

COUNT()函数可以与GROUP BY一起使用来计算每个分组的总和。

**AVG()函数()：**

AVG()函数通过计算返回的行数和每一行数据的和，求得**指定列数据的平均值**。

AVG()函数可以与**GROUP BY一起使用**，来**计算每个分组的平均值**。

**SUM()函数：**

SUM()是一个求总和的函数，返回**指定列值的总和。**

SUM()可以与GROUP BY一起使用，来计算**每个分组的总和**。

**MAX()函数：**

MAX()返回指定**列中的最大值**。

MAX()也可以和GROUP BY关键字一起使用，求每个**分组中的最大值**。

MAX()函数不仅适用于查找数值类型，也可应用于字符类型。

**MIN()函数：**

MIN()返回查询列中的最小值。

MIN()也可以和GROUP BY关键字一起使用，求出每个分组中的最小值。

MIN()函数与MAX()函数类似，不仅适用于查找数值类型，也可应用于字符类型。

### 表跟表是怎么关联的？

存储表与表之间常用的关联方式有两种：**内连接、外连接**，下面以MySQL为例来说明这两种连接方式。

**内连接：**

内连接通过**INNER JOIN**来实现，它将返回两张表中满足连接条件的数据，不满足条件的数据不会查询出来。

```sql
SELECT table1.column1, table2.column2...
FROM table1
INNER JOIN table2
ON table1.common_column1 = table2.common_column2;
```

**外连接：**

外连接通过**OUTER JOIN**来实现，它会返回两张表中满足连接条件的数据，同时返回不满足连接条件的数据。外连接有两种形式：**左外连接**（LEFT OUTER JOIN）、**右外连接**（RIGHT OUTER JOIN）。

- **左外连接**：可以简称为左连接（LEFT JOIN），它会返回**左表**中的**所有记录**和**右表**中**满足连接条件**的记录。

```sql
SELECT column_name(s)
FROM table1
LEFT OUTER JOIN table2
ON table1.column_name=table2.column_name;
```

- **右外连接**：可以简称为右连接（RIGHT JOIN），它会返回**右表**中的**所有记录**和**左表**中**满足连接条件**的记录。

```mysql
SELECT column_name(s)
FROM table1
RIGHT OUTER JOIN table2
ON table1.column_name=table2.column_name;
```

除此之外，还有一种常见的连接方式：**等值连接**。这种连接是通过WHERE子句中的条件，将两张表连接在一起，它的实际效果等同于内连接。出于语义清晰的考虑，一般更建议使用内连接，而不是等值连接。

以上是从语法上来说明表与表之间关联的实现方式，而从表的关系上来说，比较常见的关联关系有：一对多关联、多对多关联、自关联。

- **一对多关联**：这种关联形式最为常见，一般是**两张表**具有**主从关系**，并且以**主表的主键**关联**从表的外键**来实现这种关联关系。另外，以从表的角度来看，它们是具有多对一关系的，所以不再赘述多对一关联了。
- **多对多关联**：这种关联关系比较复杂，如果**两张表具有多对多的关系**，那么它们之间需要有一张**中间表**来作为**衔接**，以实现这种关联关系。这个**中间表**要**设计两列**，分别**存储那两张表的主键**。因此，这两张表中的任何一方，都与中间表形成了一对多关系，从而在这个中间表上建立起了多对多关系。
- **自关联**：自关联就是**一张表自己与自己相关联**，为了避免表名的冲突，需要在关联时通过**别名**将它们**当做两张表**来看待。一般在表中数据具有层级（树状）时，可以采用自关联一次性查询出多层级的数据。

### 说一说你对外连接的了解

外连接通过**OUTER JOIN**来实现，它会返回两张表中满足连接条件的数据，同时返回不满足连接条件的数据。常见的外连接有两种形式：**左外连接**（LEFT OUTER JOIN）、**右外连接**（RIGHT OUTER JOIN）。

- 左外连接：可以简称为左连接（LEFT JOIN），它会返回左表中的所有记录和右表中满足连接条件的记录。
- 右外连接：可以简称为右连接（RIGHT JOIN），它会返回右表中的所有记录和左表中满足连接条件的记录。

实际上，外连接还有一种形式：完全外连接（FULL OUTER JOIN），但MySQL不支持这种形式。

### SQL中怎么将行转成列？

我们以MySQL数据库为例，来说明行转列的实现方式。

首先，假设我们有一张分数表（tb_score），表中的数据如下图：

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645691385536/B7B19BEB5B3637BD6F77BAEF8C78878E)

然后，我们再来看一下转换之后需要得到的结果，如下图：

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645691399725/34B388B4E27D86F7398B0456E5F95682)

可以看出，这里行转列是将原来的subject字段的多行内容选出来，作为结果集中的不同列，并根据userid进行分组显示对应的score。通常，我们有两种方式来实现这种转换。

使用 CASE...WHEN...THEN 语句实现行转列，参考如下代码：

```mysql
SELECT userid, 
SUM(CASE `subject` WHEN '语文' THEN score ELSE 0 END) as '语文', 
SUM(CASE `subject` WHEN '数学' THEN score ELSE 0 END) as '数学', 
SUM(CASE `subject` WHEN '英语' THEN score ELSE 0 END) as '英语', 
SUM(CASE `subject` WHEN '政治' THEN score ELSE 0 END) as '政治'  
FROM tb_score  
GROUP BY userid
```

注意，SUM() 是为了能够使用GROUP BY根据userid进行分组，因为每一个userid对应的subject="语文"的记录只有一条，所以SUM() 的值就等于对应那一条记录的score的值。假如userid ='001' and subject='语文' 的记录有两条，则此时SUM() 的值将会是这两条记录的和，同理，使用Max()的值将会是这两条记录里面值最大的一个。但是正常情况下，一个user对应一个subject只有一个分数，因此可以使用SUM()、MAX()、MIN()、AVG()等聚合函数都可以达到行转列的效果。

使用IF()函数实现行转列

```mysql
SELECT userid, 
SUM(IF(`subject`='语文',score,0)) as '语文', 
SUM(IF(`subject`='数学',score,0)) as '数学', 
SUM(IF(`subject`='英语',score,0)) as '英语', 
SUM(IF(`subject`='政治',score,0)) as '政治'  
FROM tb_score  
GROUP BY userid
```

注意，IF(subject='语文',score,0) 作为条件，即对所有subject='语文'的记录的score字段进行SUM()、MAX()、MIN()、AVG()操作，如果score没有值则默认为0。

### 谈谈你对SQL注入的理解

SQL注入的原理是将**SQL代码伪装**到**输入参数**中，传递到**服务器解析并执行**的一种攻击手法。也就是说，在一些对SERVER端发起的请求参数中植入一些SQL代码，SERVER端在执行SQL操作时，会拼接对应参数，同时也将一些SQL注入攻击的“SQL”拼接起来，导致会执行一些预期之外的操作。

比如我们的登录功能，其登录界面包括用户名和密码输入框以及提交按钮，登录时需要输入用户名和密码，然后提交。此时调用接口/user/login/ 加上参数username、password，首先连接数据库，然后后台对请求参数中携带的用户名、密码进行参数校验，即SQL的查询过程。假设正确的用户名和密码为ls和123456，输入正确的用户名和密码、提交，相当于调用了以下的SQL语句。

```mysql
SELECT * FROM user WHERE username = 'ls' AND password = '123456'
```

SQL中会将#及--以后的字符串当做注释处理，如果我们使用 ' or 1=1 # 作为用户名参数，那么服务端构建的SQL语句就如下：

```mysql
select * from user where username='' or 1=1 #' and password='123456'
```

而#会忽略后面的语句，而1=1属于常等型条件，因此这个SQL将查询出所有的登录用户。其实上面的SQL注入只是在参数层面做了些手脚，如果是引入了一些功能性的SQL那就更危险了，比如上面的登录功能，如果用户名使用这个 ' or 1=1;delete * from users; #，那么在";"之后相当于是另外一条新的SQL，这个SQL是删除全表，是非常危险的操作，因此SQL注入这种还是需要特别注意的。

如何解决SQL注入

1. **严格的参数校验**

   参数校验就没得说了，在一些**不该有特殊字符的参数**中提前**进行特殊字符校验**即可。

2. **SQL预编译**

   在知道了SQL注入的原理之后，我们同样也了解到MySQL有预编译的功能，指的是**在服务器启动时**，MySQL Client把**SQL语句的模板**（**变量采用占位符进行占位**）**发送给MySQL服务器**，MySQL服务器对SQL语句的模板进行编译，编译之后根据语句的优化分析对相应的索引进行优化，在最终绑定参数时把相应的参数传送给MySQL服务器，直接进行执行，节省了SQL查询时间，以及MySQL服务器的资源，达到一次编译、多次执行的目的，除此之外，还可以防止SQL注入。

   具体是怎样防止SQL注入的呢？实际上当将绑定的参数传到MySQL服务器，MySQL服务器对参数进行编译，即填充到相应的占位符的过程中，做了转义操作。我们常用的JDBC就有预编译功能，不仅提升性能，而且防止SQL注入。

### 将一张表的部分数据更新到另一张表，该如何操作呢？

可以采用**关联更新**的方式，将一张表的部分数据，更新到另一张表内。参考如下代码：

```mysql
update b set b.col=a.col from a,b where a.id=b.id;
update b set col=a.col from b inner join a on a.id=b.id;
update b set b.col=a.col from b left Join a on b.id = a.id;
```

### WHERE和HAVING有什么区别？

**WHERE**是一个**约束声明**，使用WHERE约束来自数据库的数据，WHERE是在结果返回之前起作用的，**WHERE中不能使用聚合函数。**

**HAVING**是一个**过滤声明**，是在**查询返回结果集**以后对查询结果进行的**过滤操作**，在**HAVING**中可以**使用聚合函数**。另一方面，**HAVING子句**中不能使用除了**分组字段**和**聚合函数**之外的其他字段。

从性能的角度来说，HAVING子句中如果使用了分组字段作为过滤条件，应该替换成WHERE子句。因为WHERE可以在执行分组操作和计算聚合函数之前过滤掉不需要的数据，性能会更好。

## 引擎

1. **常用指令**

**Show engines**; 查看MySql提供的所有**存储引擎**

![img](https://img-blog.csdnimg.cn/20210130153809627.png)

只有**InnoDB具有事务**。

Show table status like “表名”：查看表的存储引擎

2. **MyISAM和InnoDB的区别**

**MyISAM**是Mysql的**默认**数据库引擎**(5.5版本之前**)。因为不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。5.5版本之后，MySql就引入了InnoDB数据库引擎。

大多数我们使用InnoDB,但是某些情况下还是可以使用MyISAM，在读密集型。如果你不介意MyISAM崩溃恢复问题的话

两者对比：

- **是否支持行级锁**：MyISAM只有**表级**锁，InnoDB支持**表级**锁和**行级**锁，默认是行级锁。
- **是否支持事务，数据崩溃后的数据恢复**：MyISAM不支持事务与数据恢复，强调的是性能，在某些方面比InnoDB快；InnoDB支持**事务**，外部键等高级数据库功能。具有**事务、回滚和崩溃修复能力的**事务安全型表。

- **是否支持外键：**MyISAM不支持，InnoDB支持。

- **是否支持MVCC(多版本并发控制)：**只有InnoDB支持

3. **InnoDB的锁的算法有三种：**

- **Record lock** 单个**行记录上的锁**
- **Gap Lock**：间隙锁，**锁定一个范围**，不包括记录本身
- **Next-key lock**：record+gap锁定一个范围，包含记录本身

## 索引

索引是一个单独的、存储在**磁盘**上的**数据库结构**，包含着对数据表里所有记录的引用指针。使用索引可以**快速找出**在**某个或多个列**中有一**特定值的行**，所有MySQL列类型都可以被索引，对相关列使用索引是提高查询操作速度的最佳途径。

**MyISAM**和**InnoDB**存储引擎只支持BTREE索引；**MEMORY**/**HEAP**存储引擎可以支持HASH和BTREE索引。

MySQL索引使用的数据库结构主要是BTree索引和哈希索引。绝大多数需求为**单条记录**查询，可以选择**哈希索引**，**查询性能最快**；**其余**大部分场景，建议选择**BTree索引**。

索引优点：

1. 通过创建**唯一索引**，可以保证数据库表中每一行数据的**唯一性**。
2. 可以大大加快数据的**查询速度**，这也是创建索引的主要原因。
3. 在实现数据的参考完整性方面，可以加速**表和表之间的连接**。
4. 在使用**分组和排序子句**进行数据**查询时**，也可以显著**减少查询中分组和排序的时间**。

增加索引也有许多不利的方面，主要表现在如下几个方面：

1. **创建索引**和**维护索引**要**耗费时间**，并且随着数据量的增加所耗费的时间也会增加。
2. 索引需要**占磁盘空间**，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸。
3. 当对表中的**数据**进行**增加、删除和修改**的时候，**索引也要动态地维护**，这样就降低了数据的维护速度。

![img](https://img-blog.csdnimg.cn/20210130154013543.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

执行SQL的过程：

![img](https://img-blog.csdnimg.cn/20210130154025917.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

执行这一句的时候，操作如下：

先会把**数据库表**从**磁盘取到内存**，然后在和语句中的**a>1比较**(cpu筛选)，然后**取出结果**。

### **InnoDB页表**

局部性原理：运行到**一个命令只需要取一个数据**，但是**CPU认为**你之后**会用到相邻的数据**，所以会把这个数据的**相邻数据从磁盘一起取出来到内存**，多取一些到内存，这样快啊。

直接**取一页**(从磁盘中取到内存)，**一页16KB**。

![img](https://img-blog.csdnimg.cn/20210130154053565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

InnoDB取的时候取16KB,除了取当前命令的数据还会取相邻数据。

![img](https://img-blog.csdnimg.cn/20210130154101321.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

取的时候，不仅取了1，还取了相邻的数据到内存

![img](https://img-blog.csdnimg.cn/20210130154105160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

User Records + Free Space： 当插入数据了，**User Records** 就会**多**，**Free Space**就会**少**

![img](https://img-blog.csdnimg.cn/20210130154112591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

### **InnoDB行格式**

![img](https://img-blog.csdnimg.cn/2021013015413382.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

如果**没有定义主键或者唯一索引**，那么会多出row_id这个，默认给你定义了。

![img](https://img-blog.csdnimg.cn/2021013015414637.png)

![img](https://img-blog.csdnimg.cn/20210130154203380.png)

记录头信息：里面包括了下一个节点的地址。

用不同的编码会不同，字符具有不同的字节。ACII一个字节一个字符。UTF-8 一个字符0~4字节

![img](C:/Users/chm/Desktop/Java学习/面经.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70-16575431820922.png)

65535不行，因为行表格里面有变长字段和NULL标志位，占了三字节。

![img](https://img-blog.csdnimg.cn/20210130154211429.png)

如果一页都放不下的话，那么格式就这样了(Compact)

### **查询步骤（主键索引/聚簇）**

**MyISAM**:**插入什么数据就显示什么数据**

**InnoDB**:**插入数据**后会**自动排序**

排好序的**好处**：

1. **查询快**，a<3,找到了4就不用看之后的了。链表方式查询慢
2. 开始分组，这样可以**快速定位**在哪部分。

![img](https://img-blog.csdnimg.cn/20210130154241925.png)

左边这一行放在PageDireraction(页目录)

![img](https://img-blog.csdnimg.cn/20210130154301731.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

先在**目录页**找，然后再去**页号**找，然后再去页目录找，最后找到数据

简化成以下：

![img](https://img-blog.csdnimg.cn/20210130154310292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

这种结构就是**B+树**！！！为什么要用B+数呢？因为一个节点可以存多个节点，但是其他二叉树只能存两个节点，相同高度，B+数存得更多。而且子节点还是相连接的，容易查询。

叶子节点：数据   非叶子节点：**主键+指针**  存的很多，比如有二层。

**Int：8 指针：6**  **一页:16KB**,  所以**一页**就会有 **16kb/14b=1170对**，存了多少对就有多个叶子节点。如果一个**叶子节点每行1kb,**那么**叶子节点也就有16条**。所以1170**16 =1W8条数据。    三层的话，1170\*1170*\*16,接近2000W。   首页在缓存，所以去找的时候只需要找两次。

B+树的一个**节点大小** = **innodb的一页** = **4个操作系统页(一页4kb)** = **16kb**(系统规定，不用纠结)

**非叶子节点存储**(索引值+指针) = **8b(以bigint类型为例)** + **6b(指针大小为6个字节)** = **14b**



![img](https://img-blog.csdnimg.cn/20210130154315752.png)

如果主键不是顺序插入，那么已有的数据库会断开，还有可能会把一条数据挤到下一页去，浪费时间！

如果是自增Id那就直接在后面直接插入即可。主键还要比较小，如果太大了，那么一页存储的行数就会被比较少了。页数就会变多，进而数的高度会变高。查询会又会更慢一些。这样的话起始页一直在变化，肯定不行。MySQL又优化了一下

![img](https://img-blog.csdnimg.cn/20210130154350574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

要**扩充**的时候，先把**第一页的内容copy放入一个**，然后**新开第二页**，最后**修改起始页的指向地址**，这样可以目录页放在缓存这样操作会更快了。

辅助索引+回表：

![img](https://img-blog.csdnimg.cn/20210130154356662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

通过**辅助索引找出主键**，然后再**去**主键索引的**B+树找寻**。

全表扫描：

一行一行查了，不会用索引了！！！

### 索引分类

1. **聚簇索引**

- 按**主键值的大小**进行**记录和页的排序**
- B+树的**叶子节点**存储的是**完整的用户记录**，就是指这个记录中**存储了所有列的值**（包括隐藏列）

![img](https://img-blog.csdnimg.cn/20210130155222264.png)

2. **主键索引**

   数据库表经常有**一列或列组合**，其值**唯一标识表中的每一行**。该列称为表的**主键**。   在数据库关系图中为表定义**主键将自动创建主键索引**，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。

3. **唯一索引**

   唯一索引要求**索引列的值必须唯一**，但允许有空值。如果是组合索引，则列值的组合必须唯一。

   主键索引是一种特殊的唯一索引，不允许有空值。

4. **单列索引和组合索引**

   单列索引即一**个索引只包含单个列**，一个表可以有多个单列索引。

   组合索引是指在表的**多个字段组合上创建的索引**，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用。使用组合索引时遵循最左前缀集合。

5. **普通索引(2次,需要回表)**

6. **哈希索引**

   哈希索引在InnoDB引擎中叫做**自适应哈希索引**，它是由数据库自身根据你的使用情况创建的，并不能认为的干预，所以叫做自适应哈希索引，采用的是**哈希表数据结构**，所以对于字典类型查询就非常的快，但是对于范围查询就不能为力了。

7. **全文索引**

   倒序索引进行

8. **空间索引**

   空间索引是对空间数据类型的字段建立的索引，MySQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING和POLYGON。MySQL使用SPATIAL关键字进行扩展，使得能够用创建正规索引类似的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MyISAM的表中创建。

### 如何创建及保存MySQL的索引？

MySQL支持多种方法在单个或多个列上创建索引：

使用CREATE TABLE创建表时，除了可以定义列的数据类型，还可以定义主键约束、外键约束或者唯一性约束，而不论创建哪种约束，在定义约束的同时相当于在指定列上创建了一个索引。创建表时创建索引的基本语法如下：

```mysql
CREATE TABLE table_name [col_name data_type] [UNIQUE|FULLTEXT|SPATIAL] [INDEX|KEY] [index_name] (col_name [length]) [ASC|DESC]
```

其中，**UNIQUE**、**FULLTEXT**和**SPATIAL**为可选参数，分别表示**唯一索引**、**全文索引**和**空间索引**；INDEX与KEY为同义词，两者作用相同，用来指定创建索引。

例如，可以按照如下方式，在id字段上使用UNIQUE关键字创建唯一索引：

```mysql
CREATE TABLE t1 (  
    id INT NOT NULL,     
    name CHAR(30) NOT NULL,     
    UNIQUE INDEX UniqIdx(id) 
);
```

在已存在的表上创建索引

在已经存在的表中创建索引，可以使用**ALTER TABLE**语句或者**CREATEINDEX**语句。

ALTER TABLE创建索引的基本语法如下：

```mysql
ALTER TABLE table_name ADD  [UNIQUE|FULLTEXT|SPATIAL] [INDEX|KEY] [index_name] (col_name[length],...) [ASC|DESC]
```

例如，可以按照如下方式，在bookId字段上建立名称为UniqidIdx的唯一索引：

```mysql
ALTER TABLE book ADD UNIQUE INDEX UniqidIdx (bookId);
```

CREATE INDEX创建索引的基本语法如下：

```mysql
CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name  ON table_name (col_name [length],...) [ASC|DESC]
```

例如，可以按照如下方式，在bookId字段上建立名称为UniqidIdx的唯一索引：

```mysql
CREATE UNIQUE INDEX UniqidIdx ON book (bookId);
```

### MySQL怎么判断要不要加索引？

1. 当**唯一性**是某种数据本身的特征时，指定唯一索引。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度。
2. 在**频繁进行排序或分组**（即进行group by或order by操作）的列上建立索引，如果待**排序的列有多个**，可以在这些列上**建立组合索引**。

### 只要创建了索引，就一定会走索引吗？

不一定

比如，在使用组合索引的时候，如果没有遵从**“最左前缀**”的原则进行搜索，则索引是不起作用的。

举例，假设在id、name、age字段上已经成功建立了一个名为MultiIdx的组合索引。索引行中按id、name、age的顺序存放，索引可以搜索id、（id,name）、（id, name, age）字段组合。如果列不构成索引最左面的前缀，那么MySQL不能使用局部索引，如（age）或者（name,age）组合则不能使用该索引查询。

### 如何判断数据库的索引有没有生效？

可以使用**EXPLAIN**语句**查看索引是否正在使用**。

举例，假设已经创建了book表，并已经在其year_publication字段上建立了普通索引。执行如下语句：

```
EXPLAIN SELECT * FROM book WHERE year_publication=1990;
```

EXPLAIN语句将为我们输出详细的SQL执行信息，其中：

- **possible_keys行**给出了MySQL在搜索数据记录时**可选用的各个索引**。
- **key行**是MySQL**实际选用的索引**。

如果possible_keys行和key行都包含year_publication字段，则说明在查询时使用了该索引。

### 如何评估一个索引创建的是否合理？

1. **避免对经常更新的表进行过多的索引**，并且**索引中的列要尽可能少**。应该经常用于查询的字段创建索引，但要避免添加不必要的字段。
2. **数据量小的表最好不要使用索引**，由于数据较少，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果。
3. **在条件表达式中经常用到的不同值较多的列上建立索引**，在**不同值**很**少**的**列**上**不要建立索引**。比如在学生表的“性别”字段上只有“男”与“女”两个不同值，因此就无须建立索引，如果建立索引不但不会提高查询效率，反而会严重降低数据更新速度。
4. 当**唯一性**是某种数据本身的特征时，指定**唯一索引**。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度。
5. 在**频繁**进行**排序或分组**（即进行group by或order by操作）的**列上建立索引**，如果待排序的列有多个，可以在这些列上建立组合索引。

### 索引是越多越好吗？

索引并非越多越好，一个表中如有**大量的索引**，不仅**占用磁盘空间**，还会影响**INSERT、DELETE、UPDATE**等语句的**性能**，因为在**表中的数据更改时**，**索引**也会进行**调整和更新**。

### 数据库索引失效了怎么办？

1. 使用**组合索引**时，需要遵循“**最左前缀**”原则；
2. 不在索引列上做任何操作，例如**计算、函数、类型转换**，会**导致索引失效**而转向全表扫描；
3. 尽量使用覆盖索引（之访问索引列的查询），减少 select * 覆盖索引能减少回表次数；
4. MySQL在使用**不等于（!=或者<>）**的时候**无法使用索引**会**导致全表扫描**；
5. **LIKE**以**通配符开头（%abc）**MySQL索引**会失效**变成全表扫描的操作；
6. **字符串不加单引号**会导致索引失效（可能发生了索引列的隐式转换）；
7. **少用or**，用它来连接时会索引失效。

### 所有的字段都适合创建索引吗？

不是。

下列几种情况，是不适合创建索引的：

1. **频繁更新**的**字段**不适合建立索引；
2. **where**条件中**用不到的字段**不适合建立索引；
3. **数据比较少**的**表**不需要建索引；
4. **数据重复**且**分布比较均匀**的的**字段**不适合建索引，例如性别、真假值；
5. 参与**列计算的列**不适合建索引。

### 说一说索引的实现原理

在MySQL中，索引是在**存储引擎层**实现的，不同存储引擎对索引的实现方式是不同的，下面我们探讨一下MyISAM和InnoDB两个存储引擎的索引实现方式。

MyISAM索引实现：

**MyISAM**引擎使用**B+Tree**作为索引结构，叶节点的data域存放的是数据记录的地址，MyISAM索引的原理图如下。这里假设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的**索引文件仅仅保存数据记录的地址**。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/B6A769BBCE3D6116F2514841EA0AB92D.png)

如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示。同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/911E67ED440AC5388F07D79E4988BD69.png)

**InnoDB索引**实现：

虽然InnoDB也使用**B+Tree**作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的**数据文件本身就是索引文件**。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，**这棵树的叶节点data域保存了完整的数据记录**。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

下图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做**聚集索引**。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表**必须有主键**（MyISAM可以没有），如果没有显式指定，则MySQL系统会**自动选择一个可以唯一标识数据记录的列作为主键**，如果不存在这种列，则MySQL**自动为InnoDB表生成一个隐含字段作为主键**，这个字段长度为**6个字节，类型为长整形**。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/E93917AAC699168036AF5C36393FFC04.png)

第二个与MyISAM索引的不同是**InnoDB的辅助索引**data域**存储相应记录主键的值而不是地址**。换句话说，InnoDB的所有辅助索引都引用主键作为data域。下图为定义在Col3上的一个辅助索引。这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是**辅助索引**搜索需要检索两遍索引：首先**检索辅助索引获得主键**，然后用**主键到主索引中检索获得记录**。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/84DF5715E092FEF25762F5F53C547640.png)

### 介绍一下数据库索引的重构过程

**什么时候需要重建索引呢？**

1. 表上频繁发生**update,delete**操作；
2. 表上发生了**alter table ..move**操作（move操作**导致了rowid变化**）。

**怎么判断索引是否应该重建？**

1. 一般看**索引是否倾斜的严重**，**是否浪费了空间**，对索引进行结构分析：

   ```mysql
   analyze index index_name validate structure;
   ```

2. 在相同的session中查询index_stats表：

   ```mysql
   select height,DEL_LF_ROWS/LF_ROWS from index_stats;
   ```

   当查询的**height>=4**（索引的深度，即从根到叶节点的高度）或**DEL_LF_ROWS/LF_ROWS>0.2**的情况下，就应该考虑重建该索引。

**如何重建索引？**

- **drop原索引**，然后再**创建索引**：

  ```mysql
  drop index index_name;
  create index index_name on table_name (index_column);
  ```

  这种方式相当耗时，一般不建议使用。

- 直接重建索引：

  ```mysql
  alter index indexname rebuild;
  alter index indexname rebuild online;
  ```

  此方法较快，建议使用。

**rebuild**是**快速重建索引**的一种有效的办法，因为它是一种**使用现有索引项来重建新索引**的方法。如果**重建索引**时**有其他用户在对这个表操作**，尽量使用带**online参数**来最大限度的**减少索引重建时**将会出现的任何**加锁问题**。由于新旧索引在建立时同时存在，因此，使用这种重建方法需要有额外的磁盘空间可供临时使用，当索引建完后把老索引删除，如果没有成功，也不会影响原来的索引。利用这种办法可以用来将一个索引移到新的表空间。

**rebuild重建索引的过程：**

1. **Rebuild**以index fast full scan或table full scan方式（采用那种方式取决于cost）**读取原索引中的数据来构建一个新的索引**，重建过程中**有排序操作**，**rebuild online执行表扫描获取数据**，重建过程中**有排序操作**；
2. Rebuild会**阻塞DML（insert、update、delete）操作**，rebuild online不会阻塞DML操作；
3. rebuild online时系统会产生一个SYS_JOURNAL_xxx的IOT类型的**系统临时日志表**，所有**rebuild online时索引的变化**都**记录在这个表**中，当**新的索引创建完成**后，**把这个表的记录维护到新的索引中去**，然后**drop掉旧的索引**，rebuild online就完成了。

重建索引过程中的注意事项：

1. 执行rebuild操作时，需要检查**表空间**是否足够；
2. 虽然说rebuild online操作允许DML操作，但还是建议在**业务不繁忙时间段进行**；
3. Rebuild操作会**产生大量Redo Log**；

### MySQL的索引为什么用B+树？

B+树由B树和索引顺序访问方法演化而来，它是为磁盘或其他直接存取辅助设备设计的一种平衡查找树，在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点，各叶子节点通过指针进行链接。如下图：

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645693350499/FB148499A73DF0C97F7930BA0466170E)

B+树索引在数据库中的一个特点就是**高扇出性**，例如在InnoDB存储引擎中，每个页的大小为**16KB**。在数据库中，**B+树的高度**一般都在**2～4层**，这意味着**查找某一键值最多只需要2到4次IO操作**，这还不错。因为现在一般的磁盘**每秒**至少可以做**100次IO操作**，2～4次的IO操作意味着查询时间只需0.02～0.04秒。

### 联合索引的存储结构是什么，它的有效方式是什么？

从本质上来说，联合索引还是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2，参考下图。另外，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，所以使用联合索引时遵循**最左前缀**集合。

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645693369847/12531E6FCCD03F60C46C9397E1DD8ACA)

### MySQL的Hash索引和B树索引有什么区别？

hash索引底层就是hash表，进行查找时，**调用一次hash函数就可以获取到相应的键值，之后进行回表查询获得实际数据**。B+树底层实现是多路平衡查找树，对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。它们有以下的不同：

- hash索引进行**等值查询更快**(一般情况下)，但是**却无法进行范围查询**。因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。
- hash索引**不支持使用索引进行排序**，原理同上。
- hash索引**不支持模糊查询**以及**多列索引的最左前缀匹配**，原理也是因为hash函数的不可预测。
- hash索引需要**回表查询数据**，而B+树在符合某些条件(**聚簇索引**，覆盖索引等)的时候可以**只通过索引完成查询**。
- hash索引虽然在**等值查询上较快，但是不稳定，性能不可预测**，当某个键值存在大量重复的时候，发生**hash碰撞**，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。

因此，在大多数情况下，直接选择B+树索引可以获得稳定且较好的查询速度。而不需要使用hash索引。

### 聚簇索引和非聚簇索引有什么区别？

在InnoDB存储引擎中，可以将B+树索引分为**聚簇索引**和**辅助索引**（非聚簇索引）。无论是何种索引，**每个页的大小都为16KB**，且不能更改。

聚簇索引是根据主键创建的一棵B+树，**聚簇索引的叶子节点存放了表中的所有记录**。辅助索引是根据索引键创建的一棵B+树，与聚簇索引不同的是，其**叶子节点仅存放索引键值**，以及该索引键值指向的主键。也就是说，如果通过辅助索引来查找数据，那么当找到辅助索引的叶子节点后，很有可能还需要根据主键值查找聚簇索引来得到数据，这种查找方式又被称为书签查找。因为辅助索引不包含行记录的所有数据，这就意味着每页可以存放更多的键值，因此其高度一般都要小于聚簇索引。

### 什么是联合索引？

联合索引是指对表上的**多个列进行索引**，联合索引的创建方法与单个索引创建的方法一样，不同之处仅在于有多个索引列。从本质上来说，联合索引还是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2，参考下图。另外，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，所以使用联合索引时遵循**最左前缀集合**。

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645693387028/585E166E07C05C8308FBAD31D36FEEC3)

### select in语句中如何使用索引？

索引是否起作用，主要取决于字段类型：

- 如果字段类型为**字符串**，需要给in查询中的数值与字符串值都需要**添加引号**，索引**才能起作用**。
- 如果字段类型为**int**，则in查询中的值**不需要添加引号**，索引也会起作用。

IN的字段，在联合索引中，按以上方法，也会起作用。

### 模糊查询语句中如何使用索引？

在MySQL中模糊查询 mobile like **‘%8765**’，这种情况是**不能使用** mobile 上的索引的，那么如果需要根据手机号码后四位进行模糊查询，可以用一下方法进行改造。

我们可以加入冗余列（MySQL5.7之后加入了虚拟列，使用虚拟列更合适，思路相同），比如 mobile_reverse，内部存储为 mobile 的倒叙文本，如 mobile为17312345678，那么 mobile_reverse 存储 87654321371，为 mobile_reverse 列建立索引，查询中使用语句 **mobile_reverse like reverse(’%5678’)** 即可。

**reverse** 是 MySQL 中的**反转函数**，这条语句相当于 **mobile_reverse like ‘8765%’** ，这种语句是**可以使用索引**的。

### JavaGuide

![img](https://img-blog.csdnimg.cn/20210130155230396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

## 事务

### 什么是事务？

事务是逻辑上的一组操作，要么都执行，要么都不执行。

![img](https://img-blog.csdnimg.cn/20210130155305550.png)

### 事务的四大特性

![img](https://img-blog.csdnimg.cn/20210130155310287.png)

ACID：

(1) **原子性**(Atomicity):事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作业；

(2) **一致性**(Consistency):执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的;

(3) **隔离性**(Isolation):并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库时独立的。

(4) **持久性**(Durability):一个事务被提交之后。它对数据库中的数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

事务可以分为以下几种类型：

- **扁平事务**：是事务类型中最简单的一种，而在实际生产环境中，这可能是使用最为频繁的事务。在扁平事务中，所有**操作都处于同一层次**，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束。处于之间的操作是原子的，要么都执行，要么都回滚。
- **带有保存点的扁平事务**：除了支持扁平事务支持的操作外，允许在事务**执行过程**中**回滚到同一事务中较早的一个状态**，这是因为可能某些事务在执行过程中出现的错误并不会对所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点（savepoint）用来通知系统应该记住事务当前的状态，以便以后发生错误时，事务能回到该状态。
- **链事务**：可视为保存点模式的一个变种。链事务的思想是：**在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。**注意，**提交事务操作**和**开始下一个事务操作**将合并为一个**原子操作**。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的。
- **嵌套事务**：是一个层次结构框架。有一个**顶层事务**（top-level transaction）**控制着各个层次的事务**。顶层事务之下嵌套的事务被称为子事务（subtransaction），其控制每一个局部的变换。
- **分布式事务**：通常是一个在**分布式环境下**运行的**扁平事务**，因此需要根据数据所在位置访问网络中的不同节点。对于分布式事务，同样需要满足ACID特性，要么都发生，要么都失效。

对于MySQL的InnoDB存储引擎来说，它支持扁平事务、带有保存点的扁平事务、链事务、分布式事务。对于嵌套事务，MySQL数据库并不是原生的，因此对于有并行事务需求的用户来说MySQL就无能为力了，但是用户可以通过带有保存点的事务来模拟串行的嵌套事务。

### MySQL的ACID特性分别是怎么实现的？

**原子性实现原理：**

实现原子性的关键，是当**事务回滚**时能够**撤销**所有已经**成功执行的sql语句**。InnoDB实现回滚靠的是**undo log**，当**事务对数据库进行修改时**，InnoDB会**生成对应的undo log**。如果**事务执行失败**或**调用了rollback**，**导致事务需要回滚**，便可以利用undo log中的信息将数据回滚到修改之前的样子。

undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作。对于**insert**，**回滚时会执行delete**。对于**delete**，**回滚时会执行insert**。对于**update**，回滚时则会**执行相反的update**，把数据改回去。

**持久性实现原理：**

InnoDB作为MySQL的存储引擎，**数据是存放在磁盘中**的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，**InnoDB提供了缓存(Buffer Pool)**，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲。当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool。当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。

Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

于是，redo log被引入来解决这个问题。当**数据修改时**，除了**修改Buffer Pool中的数据**，还会**在redo log记录这次操作**。当事务提交时，会调用fsync接口对redo log进行刷盘。如果**MySQL宕机，重启时可以读取redo log中的数据**，**对数据库进行恢复**。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。

既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：

- **刷脏是随机IO**，因为每次**修改的数据位置随机**，但写**redo log是追加操作**，属于顺序IO。
- **刷脏**是以**数据页（Page）为单位**的，**MySQL默认页大小是16KB**，**一个Page上一个小修改都要整页写入**。而**redo log中只包含真正需要写入的部分**，无效IO大大减少。

**隔离性实现原理：**

隔离性追求的是**并发情形下事务之间互不干扰**。简单起见，我们主要考虑最简单的读操作和写操作(加锁读等特殊读操作会特殊说明)，那么隔离性的探讨，主要可以分为两个方面。

第一方面，**(一个事务)写操作**对**(另一个事务)写操作**的影响：**锁机制保证隔离性**。

隔离性要求同一时刻**只能有一个事务对数据进行写操作**，InnoDB通过**锁机制**来保证这一点。锁机制的基本原理可以概括为：事务在修改数据之前，需要先获得相应的锁。获得锁之后，事务便可以修改数据。该事务操作 期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。

按照粒度，锁可以分为表锁、行锁以及其他位于二者之间的锁。表锁在操作数据时会锁定整张表，并发性能较差。行锁则只锁定需要操作的数据，并发性能好。但是由于加锁本身需要消耗资源，因此在锁定数据较多情况下使用表锁可以节省大量资源。MySQL中不同的存储引擎支持的锁是不一样的，例如MyIsam只支持表锁，而InnoDB同时支持表锁和行锁，且出于性能考虑，绝大多数情况下使用的都是行锁。

第二方面，**(一个事务)写操作**对**(另一个事务)读操作**的影响：MVCC保证隔离性。

InnoDB默认的隔离级别是**RR**（REPEATABLE READ），RR**解决脏读、不可重复读、幻读等问题**，使用的是MVCC。MVCC全称Multi-Version Concurrency Control，即**多版本的并发控制协议**。它最大的优点是**读不加锁**，因此**读写不冲突，并发性能好**。InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1. **隐藏列**：InnoDB中每行数据都有隐藏列，隐藏列中包含了本行数据的**事务id、指向undo log**的指针等。
2. **基于undo log的版本链**：每行数据的隐藏列中包含了指向undo log的指针，而**每条undo log也会指向更早版本的undo log**，从而形成一条版本链。
3. **ReadView**：通过**隐藏列和版本链**，MySQL可以**将数据恢复到指定版本**。但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务id与trx_sys快照比较，从而判断数据对该ReadView是否可见，即对事务A是否可见。

**一致性实现原理：**

可以说，一致性是事务追求的最终目标。前面提到的原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。实现一致性的措施包括：

- 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证。
- 数据库本身提供保障，例如不允许向整型列插入字符串值、字符串长度不能超过列的限制等。
- 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。



### 并发事务带来那些问题

在经典的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务(多个用户对同一数据进行操作)。并发虽然是必须的，但可能会导致以下的问题。

**脏读(写(还没提交)读)：**读正在修改的数据

当一个事务正在访问数据库并且对数据进行了修改，而这种修改还没有提交到数据库，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外个事务读取到的这个数据是”脏数据”，依据”脏数据”所作的操作可能不正确的。

**丢失修改(两写(覆盖))：**

指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据v后，第二个事务也修改了这个数据。这样第一个事务内的修改内容就会丢失，因为称为丢失修改。

**不可重复读(读写(修改)读)：**

指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问了该数据。那么，在第一个事务中的两次读数据之间，由于第二事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此成为不可重复读。

**幻读(读写(插入))：**读了写了多余数据

幻读与不可重复读类似。它发生在一个事务(T1)读取了几行数据，接着另一个并发事务(T2)插入了一些数据时。在随后的查询中，第一个事务(T1)就会发生多了一些原来不存在的记录，就好像发生了幻觉一样没所以称为幻读。

**不可重复读和幻读区别：**

**不可重复读**的重点是**修改**比如读取一条记录后发现某些列的值改变了；**幻读**的重点在于**新增或者删除**比如多次读取一条记录发现记录增多或者减少了。

### 事务隔离级别有那些？默认的是？

SQL标准执行了四个隔离级别：

**READ-UNCOMMITED(读取未提交):**最低的隔离级别，允许读取尚未提交的数据变更，可能会导致**脏读、幻读或者不可重复读**。

**READ-COMMITTED(读取已提交)：**允许读取并发事务已经提交的数据，可以**阻止脏读**，但是幻读或不可重复读仍有可能发生。

**REPEATABLE-READ(可重复读)**：对同一个字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以**阻止脏读和不可重复读**，但幻读仍有可能发生。

**SERIALIZABLE(串行化)**：最高的隔离级别，完全服从ACID的隔离级别。所有的事务一次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止**脏读、不可重复读、幻读**。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/20210130155317212.png)

Mysql的**InnoDB**存储引擎的默认支持的隔离级别是**REPEATABLE-READ(可重复读)**。

与SQL标准**不同**的地方在于**InnoDB储存引擎**在**REPEATABLE-READ**（可重复读）事务隔离级别下使用的是**Next-Key Lock锁**算法，因此可以**避免幻读**的产生，这与其他数据库系统(如SQL Server)是不同的。所以InnoDB的可重复读的隔离级别已经可以**达到**SQL的**串行化隔离级别**。

InnoDB在**分布式事务**的情况下一般会用到**SERIALIZABLE(串行化)**隔离级别。

### MySQL的事务隔离级别是怎么实现的？

InnoDB支持四种隔离级别，每种级别解决掉的问题如下表：

|                         | 脏读 | 不可重复读幻读 | 幻读 |
| :---------------------: | :--: | :------------: | :--: |
|    READ UNCOMMITTED     |  Y   |       Y        |  Y   |
|     READ COMMITTED      |  N   |       Y        |  Y   |
| REPEATABLE READ（默认） |  N   |       N        |  N   |
|      SERIALIZABLE       |  N   |       N        |  N   |

这四种隔离级别的实现机制如下：

1. READ UNCOMMITTED & READ COMMITTED：

   通过**Record Lock**算法实现了行锁，但**READ UNCOMMITTED允许读取未提交数据**，所以存在**脏读**问题。而READ COMMITTED允许读取提交数据，所以不存在脏读问题，但存在不可重复读问题。

2. REPEATABLE READ：

   使用**Next-Key Lock**算法实现了行锁，并且**不允许读取已提交**的数据，所以解决了不可重复读的问题。另外，该算法包含了间隙锁，会锁定一个范围，因此也解决了幻读的问题。

3. SERIALIZABLE：

   对每个SELECT语句后自动加上LOCK IN SHARE MODE，即为每个读取操作加一个共享锁。因此在这个事务隔离级别下，读占用了锁，对一致性的非锁定读不再予以支持。

### 事务可以嵌套吗？

可以，因为嵌套事务也是众多事务分类中的一种，它是一个层次结构框架。有一个**顶层事务控制着各个层次的事务**，顶层事务之下嵌套的事务被称为**子事务**，它控制每一个局部的变换。

需要注意的是，**MySQL数据库不支持嵌套事务**。

### 如何实现可重复读（解决幻读）？

MySQL的InnoDB引擎，在默认的**REPEATABLE READ的隔离级别**下，实现了可重复读，同时也解决了幻读问题。它使用**Next-Key Lock**算法实现了行锁，并且**不允许读取已提交的数据**，所以**解决了不可重复读**的问题。另外，该算法包含了**间隙锁**，会**锁定一个范围**，因此也解决了幻读的问题。

### MySQL事务如何回滚？

在MySQL默认的配置下，**事务**都是**自动提交和回滚**的。当显式地开启一个事务时，可以使用**ROLLBACK**语句进行回滚。该语句有两种用法：

- **ROLLBACK**：要使用这个语句的最简形式，只需发出ROLLBACK。同样地，也可以写为ROLLBACK WORK，但是二者几乎是等价的。**回滚会结束用户的事务，并撤销正在进行的所有未提交的修改**。

```mysql
BEGIN 
  DECLARE exit handler for sqlexception  -- 捕捉错误，如果是sql错误就执行里面的
  BEGIN 
    -- ERROR 
    set p_return_code = 1;  -- 返回值1,说明sql错误
    rollback;   -- 回滚数据
END; 
```

- **ROLLBACK TO [SAVEPOINT] identifier** ：这个语句与**SAVEPOINT**命令一起使用。可以把事务回滚到标记点，而不回滚在此标记点之前的任何工作。

```mysql
savepoint point_1; 创建保存点
INSERT INTO test.mylock(id, name) VALUES(6, 'f');
select * from mylock;
+----+------+
| id | name |
+----+------+
| 1 | a |
| 2 | b |
| 3 | c |
| 4 | d |
| 5 | e |
| 6 | f |
+----+------+
6 rows in set (0.03 sec)
mysql> rollback to point_1;回滚到指定保存点
```

## 锁

### 了解数据库的锁吗？

锁是数据库系统区别于文件系统的一个关键特性，锁机制用于管理对共享资源的并发访问。下面我们以MySQL数据库的InnoDB引擎为例，来说明锁的一些特点。

**锁的类型：**

InnoDB存储引擎实现了如下两种标准的行级锁：

- **共享锁**（S Lock），**允许**事务**读一行数据**。
- **排他锁**（X Lock），**允许**事务**删除或更新一行数据**。

如果一个**事务T1**已经**获得**了**行r的共享锁**，那么另外的**事务T2**可以立即**获得行r的共享锁**，因为读取并没有改变行r的数据，称这种情况为**锁兼容**。但若有其他的**事务T3想获得行r的排他锁**，则其必须**等待事务T1、T2释放行r上的共享锁**，这种情况称为**锁不兼容**。下图显示了共享锁和排他锁的兼容性，可以发现X锁与任何的锁都不兼容，而S锁仅和S锁兼容。需要特别注意的是，S和X锁都是**行锁**，兼容是指对同一记录（row）锁的兼容性情况。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/AF0C958CDABD8CEF732868BAC1FA218E.png)

**锁的粒度：**

**InnoDB存储引擎**支持**多粒度锁定**，这种锁定**允许事务在行级上的锁和表级上的锁同时存在**。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为**意向锁**。意向锁是将**锁定的对象分为多个层次**，意向锁意味着事务希望在**更细粒度上进行加锁**。

InnoDB存储引擎支持意向锁设计比较简练，其意向锁即为**表级别的锁**。设计目的主要是为了在**一个事务中揭示下一行将被请求的锁类型**。其支持两种意向锁：

- **意向共享锁**（IS Lock），事务**想要获得**一张表中**某几行的共享锁**。
- **意向排他锁**（IX Lock），事务**想要获得**一张表中**某几行的排他锁**。

由于InnoDB存储引擎支持的是行级别的锁，因此**意向锁**其实不会**阻塞**除**全表扫**以外的任何请求。故表级意向锁与行级锁的兼容性如下图所示。

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645693972061/C8651AED80A6A771DDAFBECABC9D6BED)

**锁的算法：**

InnoDB存储引擎有3种行锁的算法，其分别是： 

- **Record Lock**：**单个行**记录上的**锁**。
- **Gap Lock**：**间隙锁**，锁定一个范围，但不包含记录本身。
- **Next-Key Lock**∶**Gap Lock+Record Lock**，**锁定一个范围，并且锁定记录本身**。

**Record Lock**总是会去**锁住索引记录**，如果InnoDB存储引擎表在建立的时候**没有设置**任何一个**索引**，那么这时InnoDB存储引擎会**使用隐式的主键**来进行**锁定**。**Next-Key Lock**是**结合**了**Gap Lock**和**Record Lock**的一种锁定算法，在Next-Key Lock算法下，**InnoDB**对于**行的查询**都是**采用**这种Next-Key Lock。采用Next-Key Lock的锁定技术称为**Next-Key Locking**，其设计的目的是为了**解决Phantom Problem（幻读）**。而利用这种锁定技术，锁定的不是单个值，而是一个范围，是谓词锁（predict lock）的一种改进。

**关于死锁：**

死锁是指**两个或两个以上的事务**在执行过程中，因**争夺锁资源**而**造成**的一种**互相等待**的现象。若无外力作用，事务都将无法推进下去。

**解决死锁**问题最简单的一种方法是**超时**，即当**两个事务互相等待**时，当**一个等待时间超过设置的某一阈值时**，其中**一个事务进行回滚**，**另一个等待的事务**就能**继续进行**。

除了超时机制，当前数据库还都普遍采用**wait-for graph（等待图）**的方式来进行死锁检测。较之超时的解决方案，这是一种更为**主动的死锁检测方式**。InnoDB存储引擎也采用的这种方式。wait-for graph要求数据库保存以下两种信息：

- **锁的信息链表；**
- **事务等待链表；**

通过上述链表可以构造出一张图，而在这个**图中若存在回路**，就**代表存在死锁**，因此**资源间相互发生等待**。这是一种较为主动的死锁检测机制，在每个**事务请求锁**并**发生等待时**都会**判断是否存在回路**，若**存在**则有**死锁**，通常来说InnoDB存储引擎**选择回滚undo量最小的事务**。

![img](C:/Users/chm/Desktop/Java学习/面经.assets/242246111248980.jpg)

**锁的升级：**

锁升级（Lock Escalation）是指**将当前锁的粒度降低**。举例来说，数据库可以把一个表的1000个**行锁升级**为一个**页锁**，或者将**页锁**升级为**表锁**。

InnoDB存储引擎不存在锁升级的问题。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

### 介绍一下间隙锁

InnoDB存储引擎有3种行锁的算法，**间隙锁**（Gap Lock）是其中之一。间隙锁用于**锁定一个范围**，但**不包含记录本身**。它的作用是为了**阻止多个事务将记录插入到同一范围内**，而这会导致幻读问题的产生。

### InnoDB中行级锁是怎么实现的？

1. InnoDB行级锁是通过给**索引上的索引项加锁**来实现的。

2. 只有**通过索引条件检索数据**，**InnoDB**才**使用行级锁**，否则，**InnoDB**将**使用表锁**。

### 数据库在什么情况下会发生死锁？

死锁是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去。下图演示了死锁的一种经典的情况，即A等待B、B等待A，这种死锁问题被称为AB-BA死锁。

![img](https://uploadfiles.nowcoder.com/images/20220224/4107856_1645693986470/5600879DF5CAE148E2EF7CC23C367B6E)

### 说说数据库死锁的解决办法

解决死锁问题最简单的一种方法是超时，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。

除了超时机制，当前数据库还都普遍采用**wait-for graph（等待图）**的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB存储引擎也采用的这种方式。wait-for graph要求数据库保存以下两种信息：

- **锁的信息链表；**
- **事务等待链表；**

通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待。这是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务。

## 优化

### 对数据库优化的理解

MySQL数据库优化是多方面的，原则是**减少系统的瓶颈，减少资源的占用，增加系统的反应速度。**例如，通过优化文件系统，提高磁盘I\O的读写速度；通过优化操作系统调度策略，提高MySQL在高负荷情况下的负载能力；优化表结构、索引、查询语句等使查询响应更快。

针对**查询**，我们可以通过使用**索引**、使用连接代替子查询的方式来提高查询速度。

针对**慢查询**，我们可以通过**分析慢查询日志**，来发现引起慢查询的原因，从而有针对性的进行优化。

针对**插入**，我们可以通过**禁用索引、禁用检查**等方式来提高插入速度，在插入之后再启用索引和检查。

针对**数据库结构**，我们可以通过将字段很多的表**拆分成多张表**、**增加中间表**、**增加冗余字段**等方式进行优化。

### 该如何优化MySQL的查询？

**使用索引：**

如果查询时没有使用索引，查询语句将扫描表中的所有记录。在数据量大的情况下，这样查询的速度会很慢。如果使用索引进行查询，查询语句可以根据索引快速定位到待查询记录，从而减少查询的记录数，达到提高查询速度的目的。

索引可以提高查询的速度，但并不是使用带有索引的字段查询时索引都会起作用。有几种特殊情况，在这些情况下有可能使用带有索引的字段查询时索引并没有起作用。

1. 使用**LIKE关键字**的查询语句

   在使用LIKE关键字进行查询的查询语句中，如果匹配字符串的**第一个字符为“%”，索引不会起作用**。只有“%”不在第一个位置，索引才会起作用。

2. 使用**多列索引**的查询语句

   MySQL可以为**多个字段创建索引**。**一个索引可以包括16个字段**。对于多列索引，只有查询条件中使用了这些字段中的第1个字段时索引才会被使用。( 最左前缀匹配)

3. 使用**OR关键字**的查询语句

   查询语句的查询条件中只有OR关键字，且**OR前后的两个条件**中的**列都是索引**时，查询中**才使用索引**。否则，查询将不使用索引。

**优化子查询：**

使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。

子查询虽然可以使查询语句很灵活，但执行效率不高。执行子查询时，MySQL需要为内层查询语句的查询结果建立一个临时表。然后外层查询语句从临时表中查询记录。查询完毕后，再撤销这些临时表。因此，子查询的速度会受到一定的影响。如果查询的数据量比较大，这种影响就会随之增大。

在MySQL中，可以使用**连接（JOIN）查询来替代子查询**。连接查询不需要建立临时表，其速度比子查询要快，如果查询中使用索引，性能会更好。

### 怎样插入数据才能更高效？

影响插入速度的主要是**索引**、**唯一性校验**、**一次插入记录条数**等。针对这些情况，可以分别进行优化。

对于**MyISAM**引擎的表，常见的优化方法如下：

1. **禁用索引**

   对于非空表，插入记录时，MySQL会根据表的索引对插入的记录建立索引。如果插入大量数据，**建立索引会降低插入记录的速度。**为了解决这种情况，可以在**插入记录之前禁用索引，数据插入完毕后再开启索引**。对于空表批量导入数据，则不需要进行此操作，因为MyISAM引擎的表是在导入数据之后才建立索引的。

2. **禁用唯一性检查**

   插入数据时，MySQL会对插入的记录进行**唯一性校验**。这种唯一性校验也会降低插入记录的速度。为了降低这种情况对查询速度的影响，可以在插入记录之前禁用唯一性检查，等到记录插入完毕后再开启。

3. **使用批量插入**

   插入多条记录时，可以使用一条INSERT语句插入一条记录，也可以使用一条INSERT语句插入多条记录。使用一条INSERT语句插入多条记录的情形如下，而这种方式的插入速度更快。

   ```mysql
   INSERT INTO fruits VALUES ('x1', '101', 'mongo2', '5.7'), ('x2', '101', 'mongo3', '5.7'), ('x3', '101', 'mongo4', '5.7');
   ```

4. 使用**LOAD DATA INFILE**批量导入（高速地从一个文本文件中读取行，并写入一个表中。）

   当需要批量导入数据时，如果能用**LOAD DATA INFILE**语句，就尽量使用。因为LOAD DATA INFILE语句导入数据的速度比INSERT语句快。

对于**InnoDB**引擎的表，常见的优化方法如下：

1. **禁用唯一性检查**

   插入数据之前执行set unique_checks=0来**禁止对唯一索引的检查**，数据导入完成之后再运行set unique_checks=1。这个和MyISAM引擎的使用方法一样。

2. **禁用外键检查**

   插入数据之前执行**禁止对外键的检查**，数据插入完成之后再恢复对外键的检查。

3. **禁用自动提交**

   插入数据之前禁止事务的自动提交，数据导入完成之后，执行恢复自动提交操作。

### 表中包含几千万条数据该怎么办？

建议按照如下顺序进行优化：

1. **优化SQL和索引**；
2. **增加缓存**，如memcached、redis；
3. **读写分离**，可以采用**主从复制**，也可以采用**主主复制**；
4. 使用MySQL自带的分区表，这对应用是透明的，无需改代码，但SQL语句是要针对分区表做优化的；
5. 做**垂直拆分**，即根据模块的耦合度，将一个大的系统分为多个小的系统；
6. 做**水平拆分**，要选择一个合理的sharding key，为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表。

### MySQL的慢查询优化有了解吗？

优化MySQL的慢查询，可以按照如下步骤进行：

**开启慢查询日志：**

MySQL中慢查询日志**默认**是**关闭**的，可以通过配置文件my.ini或者my.cnf中的log-slow-queries选项打开，也可以在MySQL服务启动的时候使用--log-slow-queries[=file_name]启动慢查询日志。

启动慢查询日志时，需要在my.ini或者my.cnf文件中配置long_query_time选项指定记录阈值，如果某条查询语句的查询时间超过了这个值，这个查询过程将被记录到慢查询日志文件中。

分析慢查询日志：

直接分析mysql慢查询日志，利用explain关键字可以模拟优化器执行SQL查询语句，来分析sql慢查询语句。

**常见慢查询优化：**

1. **索引没起作用**的情况

   - 在使用**LIKE关键字**进行查询的查询语句中，如果匹配字符串的第一个字符为“%”，索引不会起作用。只有“%”不在第一个位置，索引才会起作用。
   - MySQL可以为**多个字段创建索引**。一个索引可以包括16个字段。对于多列索引，只有查询条件中使用了这些字段中的第1个字段时索引才会被使用。
   - 查询语句的查询条件中只有**OR关键字**，且OR前后的两个条件中的列都是索引时，查询中才使用索引。否则，查询将不使用索引。

2. **优化数据库结构**

   - 对于字段比较多的表，如果**有些字段的使用频率很低，可以将这些字段分离出来形成新表**。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。
   - 对于**需要经常联合查询的表，可以建立中间表以提高查询效率**。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询，以此来提高查询效率。

3. **分解关联查询**

   很多高性能的应用都会对**关联查询进行分解**，就是可以对每一个表进行一次单表查询，然后将查询结果在应用程序中进行关联，很多场景下这样会更高效。

4. **优化LIMIT分页**

   当**偏移量非常大**的时候，例如可能是limit 10000,20这样的查询，这是mysql需要查询10020条然后只返回最后20条，前面的10000条记录都将被舍弃，这样的代价很高。优化此类查询的一个最简单的方法是**尽可能的使用索引覆盖扫描**，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。对于偏移量很大的时候这样做的效率会得到很大提升。

### 说一说你对explain的了解

MySQL中提供了EXPLAIN语句和DESCRIBE语句，用来分析查询语句，EXPLAIN语句的基本语法如下：

```mysql
EXPLAIN [EXTENDED] SELECT select_options
```

使用EXTENED关键字，EXPLAIN语句将产生附加信息。执行该语句，可以**分析EXPLAIN后面SELECT语句的执行情况**，并且能够分析出所查询表的一些特征。下面对查询结果进行解释：

- id：SELECT识别符。这是SELECT的查询序列号。
- select_type：表示SELECT语句的类型。
- table：表示查询的表。
- type：表示表的连接类型。
- possible_keys：给出了MySQL在搜索数据记录时可选用的各个索引。
- key：是MySQL实际选用的索引。
- key_len：给出索引按字节计算的长度，key_len数值越小，表示越快。
- ref：给出了关联关系中另一个数据表里的数据列名。
- rows：是MySQL在执行这个查询时预计会从这个数据表里读出的数据行的个数。
- Extra：提供了与关联操作有关的信息。

**DESCRIBE**语句的使用方法与**EXPLAIN**语句是一样的，分析结果也是一样的，并且可以缩写成DESC。。DESCRIBE语句的语法形式如下：

```mysql
DESCRIBE SELECT select_options
```

### explain关注什么？

重点要关注如下几列：

|  列名   |                             备注                             |
| :-----: | :----------------------------------------------------------: |
|  type   |  本次查询**表联接类型**，从这里可以看到本次查询大概的效率。  |
|   key   | **最终选择的索引**，如果没有索引的话，本次查询效率通常很差。 |
| key_len |           本次查询**用于结果过滤的索引实际长度**。           |
|  rows   |   **预计需要扫描的记录数**，预计需要扫描的记录数越小越好。   |
|  Extra  | 额外附加信息，主要确认是否出现 Using filesort、Using temporary 这两种情况。 |

其中，type包含以下几种结果，从上之下依次是最差到最好：

|      类型       |                             备注                             |
| :-------------: | :----------------------------------------------------------: |
|       ALL       |          执行full table scan，这是最差的一种方式。           |
|      index      | 执行full index scan，并且可以通过索引完成结果扫描并且直接从索引中取的想要的结果数据，也就是可以避免回表，比ALL略好，因为索引文件通常比全部数据要来的小。 |
|      range      |             利用索引进行范围查询，比index略好。              |
| index_subquery  |                    子查询中可以用到索引。                    |
| unique_subquery |   子查询中可以用到唯一索引，效率比 index_subquery 更高些。   |
|   index_merge   |     可以利用index merge特性用到多个索引，提高查询效率。      |
|   ref_or_null   |    表连接类型是ref，但进行扫描的索引列中可能包含NULL值。     |
|    fulltext     |                          全文检索。                          |
|       ref       |            基于索引的等值查询，或者表间等值连接。            |
|     eq_ref      |   表连接时基于主键或非NULL的唯一索引完成扫描，比ref略好。    |
|      const      | 基于主键或唯一索引唯一值查询，最多返回一条结果，比eq_ref略好。 |
|     system      |           查询对象表只有一行数据，这是最好的情况。           |

另外，Extra列需要注意以下的几种情况:

|            关键字            | 备注                                                         |
| :--------------------------: | :----------------------------------------------------------- |
|        Using filesort        | 将用外部排序而不是按照索引顺序排列结果，数据较少时从内存排序，否则需要在磁盘完成排序，代价非常高，需要添加合适的索引。 |
|       Using temporary        | 需要创建一个临时表来存储结果，这通常发生在对没有索引的列进行GROUP BY时，或者ORDER BY里的列不都在索引里，需要添加合适的索引。 |
|         Using index          | 表示MySQL使用覆盖索引避免全表扫描，不需要再到表中进行二次查找数据，这是比较好的结果之一。注意不要和type中的index类型混淆。 |
|         Using where          | 通常是进行了全表/全索引扫描后再用WHERE子句完成结果过滤，需要添加合适的索引。 |
|       Impossible WHERE       | 对Where子句判断的结果总是false而不能选择任何数据，例如where 1=0，无需过多关注。 |
| Select tables optimized away | 使用某些聚合函数来访问存在索引的某个字段时，优化器会通过索引直接一次定位到所需要的数据行完成整个查询，例如MIN()\MAX()，这种也是比较好的结果之一。 |

### 大表的优化

当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化性能措施如下：

**限定数据的范围**

**禁止不带**任何**限制数据范围条件**的**查询语句**。比如：当用户查询订单历史的时候，我们可以控制在一个月的范围内；

**读/写分离**

经典的数据库拆分方案，**主库负责写**，**从库负责读**；

**垂直分区**

**根据数据库里面数据表的相关性进行拆分**。例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

![img](https://img-blog.csdnimg.cn/20210130155343234.png)

优点：从上图可以看出，表的列变少了，进而Lock数会变少，I/O次数也会变少。简化了表的结构，易于维护。

缺点：从上图可以看出，多出了1的列！**主键会出现冗余**，需要管理冗余列，并引起Join操作，可以通过在应用层Join。表多了所以会让事务变得复杂。

**水平分区**

如果水平分区在一台机器上是没效果的，因为始终是一台cpu在进行查询。

水平拆分能够支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度。一般在优化得当的情况千万级数据量没问题。如果非要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

## 其他

### 介绍一下数据库设计的三大范式

**第一范式（1NF）：**

是指在关系模型中，对于添加的一个规范要求，**所有的域**都应该是**原子性**的，即数据库表的**每一列**都是**不可分割的原子数据项**，而不能是集合，数组，记录等非原子数据项。

即实体中的某个属性有多个值时，必须拆分为不同的属性。在符合第一范式表中的每个域值只能是实体的一个属性或一个属性的一部分。简而言之，第一范式就是无重复的域。

**第二范式（2NF）：**

在1NF的基础上，**非码属性必须完全依赖于候选码**（在1NF基础上消除非主属性对主码的部分函数依赖）。

第二范式是在第一范式的基础上建立起来的，即满足第二范式必须先满足第一范式。第二范式要求数据库表中的每个实例或记录必须可以被唯一地区分。选取一个能区分每个实体的属性或属性组，作为实体的唯一标识。

例如在员工表中的身份证号码即可实现每个一员工的区分，该身份证号码即为候选键，任何一个候选键都可以被选作主键。在找不到候选键时，可额外增加属性以实现区分，如果在员工关系中，没有对其身份证号进行存储，而姓名可能会在数据库运行的某个时间重复，无法区分出实体时，设计辟如ID等不重复的编号以实现区分，被添加的编号或ID选作主键。

**第三范式（3NF）：**

在2NF基础上，**任何非主属性不依赖于其它非主属性**（在**2NF**基础上**消除传递依赖**）。

第三范式是第二范式的一个子集，即满足第三范式必须满足第二范式。简而言之，第三范式要求一个关系中不包含已在其它关系已包含的非主关键字信息。

例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。

### 说一说你对MySQL引擎的了解

MySQL提供了多个不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。MySQL 8.0支持的存储引擎有InnoDB、MyISAM、Memory、Merge、Archive、Federated、CSV、BLACKHOLE等。其中，最常用的引擎是InnoDB和MyISAM。

**InnoDB存储引擎：**

InnoDB是**事务型数据库的首选引擎**，支持事务安全表（ACID），支持行锁定和外键。MySQL 5.5.5之后，**InnoDB作为默认存储引擎**，主要特性如下：

1. InnoDB给MySQL提供了具有**提交、回滚和崩溃恢复能力**的**事务安全（ACID兼容）存储引擎**。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表与其他MySQL表的类型混合起来，甚至在同一个查询中也可以混合。
2. InnoDB是为**处理巨大数据量**的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系数据库引擎所不能匹敌的。
3. InnoDB存储引擎完全与MySQL服务器整合，为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引存在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘分区）。这与MyISAM表不同，比如在MyISAM表中每个表被存在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上。
4. InnoDB支持外键完整性约束（FOREIGN KEY）。存储表中的数据时，每张表的**存储**都**按主键顺序存放**，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6B的ROWID，并以此作为主键。
5. InnoDB被用在众多需要高性能的大型数据库站点上。InnoDB不创建目录，使用InnoDB时，MySQL将在数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件。

**MyISAM存储引擎：**

MyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM**拥有较高的插入、查询速度**，但不支持事务。MyISAM的主要特性如下：

1. 在支持大文件（达63位文件长度）的文件系统和操作系统上被支持。
2. 当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块以及若下一个块被删除则扩展到下一块来自动完成。
3. 每个MyISAM表最大的索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16个。
4. 最大的键长度是1000B，这也可以通过编译来改变。对于键长度超过250B的情况，一个超过1024B的键将被用上。
5. BLOB和TEXT列可以被索引。
6. NULL值被允许在索引的列中，这个值占每个键的0~1个字节。
7. 所有数字键值以高字节优先被存储，以允许一个更高的索引压缩。
8. 每个表一个AUTO_INCREMENT列的内部处理。MyISAM为INSERT和UPDATE操作自动更新这一列，这使得AUTO_INCREMENT列更快（至少10%）。在序列顶的值被删除之后就不能再利用。
9. 可以把数据文件和索引文件放在不同目录。
10. 每个字符列可以有不同的字符集。
11. 有VARCHAR的表可以固定或动态记录长度。
12. VARCHAR和CHAR列可以多达64KB。

### 说一说你对redo log、undo log、binlog的了解

**binlog（Binary Log）：**

二进制日志文件就是常说的binlog。**二进制日志记录了MySQL所有修改数据库的操作**，然后以二进制的形式记录在日志文件中，其中还包括每条语句所执行的时间和所消耗的资源，以及相关的事务信息。

默认情况下，二进制日志功能是开启的，启动时可以重新配置--log-bin[=file_name]选项，修改二进制日志存放的目录和文件名称。

**redo log：**

重做日志用来实现事务的持久性，即事务ACID中的D。它由两部分组成：一是**内存中的重做日志缓冲**（redo log buffer），其是易失的；二是**重做日志文件**（redo log file），它是持久的。

InnoDB是事务的存储引擎，它通过**Force Log at Commit**机制**实现事务的持久性**，即当事务提交（COMMIT）时，必须先**将该事务的所有日志写入到重做日志文件**进行持久化，待事务的COMMIT操作完成才算完成。这里的日志是指重做日志，在InnoDB存储引擎中，由两部分组成，即redo log和undo log。

redo log用来保证事务的持久性，undo log用来帮助事务回滚及MVCC的功能。redo log基本上都是顺序写的，在数据库运行时不需要对redo log的文件进行读取操作。而undo log是需要进行随机读写的。

**undo log：**

重做日志**记录了事务的行为**，可以很好地通过其对页进行“重做”操作。但是**事务**有时还**需要**进行**回滚操作**，这时就**需要undo**。因此在对数据库进行修改时，InnoDB存储引擎不但会产生redo，还会产生一定量的undo。这样如果用户执行的事务或语句由于某种原因失败了，又或者用户用一条ROLLBACK语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。

redo存放在重做日志文件中，与redo不同，**undo**存放在**数据库内部**的一个**特殊段**（segment）中，这个段称为undo段（undo segment），undo段位于共享表空间内。

undo log是**把所有没有COMMIT的事务回滚到事务开始前的状态**，系统崩溃时，可能有些事务还没有COMMIT，在系统恢复时，这些没有COMMIT的事务就需要借助undo log来进行回滚。

### 谈谈你对MVCC的了解

InnoDB默认的隔离级别是RR（REPEATABLE READ），**RR解决脏读、不可重复读、幻读等问题**，使用的是MVCC。MVCC全称Multi-Version Concurrency Control，即**多版本的并发控制协议**。它最大的优点是**读不加锁**，因此**读写不冲突**，**并发性能好**。InnoDB实现MVCC，多个版本的数据可以共存，主要基于以下技术及数据结构：

1. **隐藏列**：InnoDB中每行数据都有隐藏列，隐藏列中包含了**本行数据的事务id、指向undo log的指针**等。
2. **基于undo log的版本链**：每行数据的隐藏列中包含了指向undo log的指针，而**每条undo log也会指向更早版本的undo log**，从而形成一条版本链。
3. **ReadView**：通过**隐藏列和版本链**，MySQL可以**将数据恢复到指定版本**。但是具体要恢复到哪个版本，则需要根据ReadView来确定。所谓ReadView，是指事务（记做事务A）在**某一时刻给整个事务系统（trx_sys）打快照**，之后再进行**读操作**时，会将读取到的数据中的**事务id与trx_sys快照**比较，从而**判断数据对该ReadView是否可见，即对事务A是否可见**。

### MySQL主从同步是如何实现的？

复制（replication）是MySQL数据库提供的一种高可用高性能的解决方案，一般用来建立大型的应用。总体来说，replication的工作原理分为以下3个步骤：

1. **主服务器**（master）把**数据更改记录**到**二进制日志**（binlog）中。
2. **从服务器**（slave）把**主服务器的二进制日志复制到自己的中继日志**（relay log）中。
3. **从服务器重做中继日志中的日志**，把**更改应用到自己的数据库**上，以**达到数据**的最终**一致性。**

复制的工作原理并不复杂，其实就是一个完全备份加上二进制日志备份的还原。不同的是这个二进制日志的还原操作基本上实时在进行中。这里特别需要注意的是，复制不是完全实时地进行同步，而是**异步实时**。这中间存在主从服务器之间的执行延时，如果主服务器的压力很大，则可能导致主从服务器延时较大。复制的工作原理如下图所示，其中从服务器有2个线程，一个是I/O线程，负责读取主服务器的二进制日志，并将其保存为中继日志；另一个是SQL线程，复制执行中继日志。

## 池化设计思想。什么是数据库连接池？为什么需要数据库连接池？

这种设计是预设资源 ，解决的问题是**避免**每次**获取**资源的**消耗**。如**创建线程的开销,获得远程连接的开销**。就好比你去食堂打饭，食堂阿姨会先把饭盛好几份，有人来了就直接给他，而不是来了之后再进行打饭，这样就节约时间了。除了预设资源，池化设计还包括：池子的初始值、活跃值、最大值等。

数据库的连接本质就是一个Socket的连接。数据库服务端要维护一些缓存和用户信息等。我们可以把数据库连接池是看做是维护的数据库连接的缓存，以便将来对数据进行请求的时候可以重用这些连接。**在连接池中，创建连接后，把连接放进池子中，下次连接的时候，直接从池子里取**，这样就会**减少用户与数据库的之间的连接时间**。

## 分库分表之后，id主键如何处理？

因为要是分成多个表之后，每个表都是从1开始累加，那肯定是不对的。因为分表的前提是因为一个表太多了，为了查询更快才分出来，所以不可能出现id会相同的，此时需要一个全局唯一的Id来支持。

生成全局Id有下面这几种方法：

**UUID**：是**通用唯一识别码**，是一种软件建构的标准，太长，32个16位数字，查询效率比较低，主键长，空间大，那么每页能存的就少。比较适合用于生成唯一的名字的标识比如文件的名字。

**数据库自增id**：两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的id有序，但是需要**独立步数数据库实例，成本高，还会有性能瓶颈**。

**利用redis生成id**:性能表较好，灵活方便，不依赖数据库。但是引入了redis的新组件会造成系统更加复杂，可用性降低，增加系统成本。

**Twitter的snowflake算法**：64位的整数(1位标识+41时间戳+10位节点+12位序列号)

**美团的Leaf分布式ID生成系统**：能保证全局唯一性、趋势递增、单调递增、信息安全，但也需要关系型数据库、Zookeeper等中间件。

## 一条SQL语句在Mysql中如何执行的

![img](https://img-blog.csdnimg.cn/20210130155432272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

主要分为Server层与储存引擎：

**Server层：**

客服端要连接Mysql， 

第一，**连接器**来**连接**；

第二，**分析器**分析**客户端给的sql是否正确**；

第三，**优化器**选**最优查询方法**！比如查一个id=1 name=“万小猿”  到底是先筛选那个字段呢？这就是优化器做的。

第四，**执行器调用存储引擎**去**执行sql**。

**储存引擎层：**

主要负责**数据的存储和读取**，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是InnoDB**，它从**MySQL 5.5.5**版本开始就被当做默认存储引擎了。

**查询语句：**

权限校验 -》查询缓存 -》**分析器** -》**优化器** -》权限校验 -》**执行器** -》引擎

​       连接器   分析器   优化器    执行器(执行前权限检验是否能执行)

**更新语句：**

分析器-》权限校验-》执行器-》引擎-》redo log prepare->binlog->redo log commit

Redo是InnoDB引擎独有，binlog是Mysql的日志。InnoDB引擎先把**数据保存在内存**中，同时**记录在redo log**，这个时候**redo log进入prepare状态**，然后**告诉执行器，随时可以进行提交**，然后**执行器收到通知后记录binlog**，然后**调用引擎接口**，**提交redo log**为提交状态。

![img](https://img-blog.csdnimg.cn/20210130155508421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjYyMzcy,size_16,color_FFFFFF,t_70)

## 一条SQL语句执行得很慢的原因有那些？

1. 大多数情况是正常的，只是偶尔会出现很慢的情况。

2. 在数据量不变的情况下，这条SQL语句一直以来都执行的很慢。

**针对偶尔很慢的情况**

1.数据库在刷新脏页（flush）我也无奈啊

当我们要往数据库插入一条数据、或者更新一条数据的时候，我们知道**数据**会**在内存中把对应字段的数据更新**了，但是更新之后，这些更新的字段并**不会马上同步持久到磁盘中去**，而是把这些更新的记录**写入到redo log日记中**去，等到**空闲**的时候，再通过**redo log里的日历把最新的数据同步到磁盘中去**。

![img](https://img-blog.csdnimg.cn/20210130155529631.png)

刷新脏页有下面4 点

种场景(后两种不用太关注“性能问题”)：

1. **Redolog写满了**：因为执行sql的更新语句的时候，如果更新很多的话，很有可能relog里面有很多语句都处于commit状态，还未到从内存提取到硬盘去,所以这边想进入redolog的prepare状态是不行的，要等redolog里面的内容执行完后(SQL语句慢)，才会执行新的更新语句。

2. **内存不够**：如果一次查询较多的数据，恰好所要查询的**数据页不在内存**中，需要把查询的内容从硬盘放入内存中，但是内存中是**脏页**，所以先要把内存中的**脏页写入硬盘**后，然后把硬盘中所需页取到内存中，去执行这个sql所需要的数据。

3. **Mysql认为系统空闲:**因为要从redo-prepare到commit，将内存的东西同步到硬盘，

4. **MySQL正常关闭的时候：**这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读取诗句，启动速度会很快。

2**.拿不到锁**，我能怎么办

 我们要执行表或者行操作的时候，**别的进程在进行操作**，所以只能等着别人释放，才能操作。

 判断是否在等待锁，我们可以用show processlist这个命令来查看当前的状态。

**针对一直都这么慢的情况**

**索引**没有用上

**1.字段没有索引**

如果字段没有索引，那么只有走全表扫描，把你等到花儿谢

**2.字段有索引，但却没有用索引(左边运算了)**

你给下面这个sql的c字段加了索引，但是用不到的。

![img](https://img-blog.csdnimg.cn/20210130155612694.png)

因为**左边做了运算**，就**不会用上索引**！所以想用上索引，就要这样写：

![img](https://img-blog.csdnimg.cn/20210130155616529.png)

**3.函数操作导致没有用上索引**

如果我们对字段进行**函数操作**后，也会导致没有用上索引。

![img](https://img-blog.csdnimg.cn/20210130155620542.png)

数据库自己选错索引了

如我们在进行查询操作的时候：

![img](https://img-blog.csdnimg.cn/20210130155625900.png)

C的索引可以是主键索引或者是非主键索引。如果是主键索引那么直接查最快。但是如果c是非主键索引的话，那么就有一种可能：系统根据判断误走了全局查询。为什么呢？

因为非主键索引，索引所存的值是主键的值，所以用**非主键索引查询**他是**需要两次查询**的，然后**系统评估非主键索引快还是全局扫描快**。

为什么会有误判呢？

既然要误判，那我们首先先要把判断搞清楚：进行**非主键索引**的时候，系统会**判断**这个**非主键索引的基数**(基数：比如性别是索引，那么基数为2；如果骰子(六面)点数是索引，基数为6)。比如数基数很小，那么索引查出某个字段(比如男)那么也会查询出一半的数，那么索引就没有意义了。

**所以**，**基数越大**那么**索引查询的效果越好**！！然后根据**基数的大小**，系统**选择**用索引还是全表扫描。但是**系统不可能去扫描全部的基数**，只是**采样计算**！！那么采样就意味着是随机！！刚好这次采样结果是基数很小，所以就选择了全表扫描而不是索引，导致慢起来了。这就是统计随机的结果！

但是，我们可以强制走索引的方式来查询：

![img](https://img-blog.csdnimg.cn/20210130155631875.png)

 当然我们也可以去查询索引的基数

![img](https://img-blog.csdnimg.cn/20210130155635950.png)

可查询出下列表格：

![img](https://img-blog.csdnimg.cn/20210130155639556.png)

Cardinality是基数，如果和实际基数差距太大，那么可以用下面语句重新计算一次看看，然后再看索引。

![img](https://img-blog.csdnimg.cn/20210130155643177.png)

因为选索引的时候会导致随机计算采样，所以当sql语句有多个索引的时候(mysql只能选择一个索引)，如果我没有指定，那么只能由mysql的优化器自己去决定使用哪个索引，所以有可能mysql采样随机导致选错了索引，查询变慢。

**总结**

**偶尔比较慢：**

1. 数据库在刷新脏页（flush）

2. 拿不到锁，其他进行将表或者行一直锁着。

**一直很慢：**

1. 没有用上索引

2. 数据库自己判断，选错索引

- 